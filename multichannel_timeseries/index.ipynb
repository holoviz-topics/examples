{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Channel Timeseries\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Visualizing time series from various sources on a vertically stacked, time-aligned display is often the first tool employed when working with data from [electrophysiological](https://en.wikipedia.org/wiki/Electrophysiology) studies. These experiments generally seek to provide insight into the activities of nerve cells or muscles, as well as how they relate to each other or other measurable variables, such as the spatial position of the organism under study. Electrophysiological recording sessions can include diverse data types like electromyograms (EMG), electroencephalograms (EEG), local field potentials (LFP), or neural action potentials (spikes) - each consisting of multiple streams of information ('channels') that all are unified by their alignment to a single series of timestamps, but having a heterogenuous range of amplitude values.\n",
    "\n",
    "There are many different approaches for a visualization of multichannel timeseries data, but we'll highlight the one that we've found to be promising in many scenarios. If you have a dataset that is too large to fit into memory, check out the alternate approaches in the 'Extensions and Alternate Workflows' below the Recommended Workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Make Key Features list into a diagram or gif showing the feature-components of the viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Features\n",
    "Analyzing electrophysiological data often involves searching for patterns across time, channels, and covariates. Features that support this type of investigation for time-aligned, amplitude-diverse data include:\n",
    "\n",
    "- **Smooth Interactions at Scale:** Smooth zooming and panning across time and channels.\n",
    "- **Subcoordinate Axes:** Independent amplitude dimension (y-axis) per channel.\n",
    "- **Instant Inspection:** Quick information preview about the data under the cursor.\n",
    "- **Group-Aware Handling:** Zooming and y-range normalization per specified channel group/type.\n",
    "- **Reference View:** Minimap for navigation and contextualization in large datasets.\n",
    "- **Responsive Scale Bar:** Dynamic amplitude reference measurement.\n",
    "- **Time-Range Annotations:** Create and edit time-range annotations directly on the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👉 [Recommended Workflow](./multichan.ipynb) (Start Here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./assets/240716b_multi-chan-ts.png' alt=\"Multichannel timeseries recommended workflows\" align=\"right\" width=60%>\n",
    "\n",
    "The [recommended multichannel timeseries notebook](./multichan.ipynb) provides a workflow for processing and analyzing multi-channel timeseries datasets that fit in memory.\n",
    "\n",
    "It covers the importance of live downsampling using algorithms that maintain the signal shape and optimize browser performance.\n",
    "\n",
    "Although it features the MNE-Python library for handling and visualization of raw EEG data, the concepts and methods are applicable to various timeseries data beyond EEG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions and Alternate Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add thumbnails to table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Title | Preview | Type | Summary | Details |\n",
    "|---|---|---|---|---|\n",
    "| [Larger Dataset <br> (> RAM)](./large_multichan.ipynb) | <img src=\"./thumbnails/large_multichan.png\" alt=\"Larger Dataset\" width=\"500\"> | **Alternate Workflow** | Utilize Xarray, Zarr, and Dask for dynamic access of data subsets at optimal resolution. | To handle datasets beyond available memory (RAM), we can utilize dynamic access of certain data ranges and resolutions, using a precomputed hierarchical array pyramid. |\n",
    "| [Smaller Dataset <br> (<100k samples)](./small_multi-chan-ts.ipynb) | ![Smaller Dataset](https://placehold.jp/3d4070/ffffff/500x500.png?text=Smaller%20Dataset) | **Alternate Workflow** | Minimal imports for a flexible approach with very small dataset. | Only imports HoloViz libraries, Bokeh, and Numpy. Datasets with <100k data points and <10 channels can often be handled comfortably by modern desktop browsers on well-equipped devices. |\n",
    "| [Minimap Widget](./minimap.ipynb) | ![Minimap Widget](https://placehold.jp/3d4070/ffffff/500x500.png?text=Minimap%20Widget) | Extension | Use HoloViews RangeToolLink and Datashader to rasterize an aggregate view. | Create a minimap widget that provides a condensed overview of the entire dataset, allowing users to select and zoom into areas of interest quickly in the main plot while maintaining the contextualization of the zoomed out view. |\n",
    "| [Time Range Annotation](./time_range_annotation.ipynb) | ![Time Range Annotation](https://placehold.jp/3d4070/ffffff/500x500.png?text=Time%20Range%20Annotation) | Extension | Utilize HoloNote along with any primary workflow approach. | Create (or import), edit, and save a table of start and end times. View the categorized ranges overlaid on the multi-channel timeseries plot. HoloNote allows you to interact with time range annotations directly on a plot, through widgets, or programmatically. |\n",
    "| [Standalone App](./medium_multi-chan-ts.ipynb#extension-standalone-app) | ![Standalone App](https://placehold.jp/3d4070/ffffff/500x500.png?text=Standalone%20App) | Extension | Deploy the visualization as a standalone, template-styled web application using HoloViz Panel.  | This extension shows how to wrap your plot within a Panel Template for a styled, interactive web app that can run outside of a Jupyter Notebook. By marking the Panel component as servable, you can launch the app directly from the command line, providing a user-friendly interface in its own browser window. |\n",
    "| [⚠️ (WIP) Scale Bar](./medium_multi-chan-ts.ipynb#scale-bar-extension) | ![Scale Bar](https://placehold.jp/3d4070/ffffff/500x500.png?text=Scale%20Bar%20(WIP)) | Extension | Provides an accurate, dynamic, and customizable reference gauge of signal amplitude. | The scale bar feature in HoloViews+Bokeh allows for precise measurement indicators on plots. **WIP STATUS**: As of August 2024, a [Bokeh PR](https://github.com/bokeh/bokeh/pull/14005) is being finalized to support scale bars on individual subplots within composite figures, a feature critical for multi-timeseries visualizations. Once the PR is merged, HoloViews will quickly implement support. |\n",
    "| ⚠️ (WIP) Streaming | ![Streaming](https://placehold.jp/3d4070/ffffff/500x500.png?text=Streaming%20(WIP)) | **Alternate Workflow** | Stream real-time data into a multi-channel timeseries visualization with dynamic interaction capabilities. | The streaming visualization is designed to automatically follow the incoming data stream unless the user interacts by zooming in or panning, at which point the view stays in the range that the user has navigated to. When the user resets the view from the toolbar, the visualization resumes following the live data stream. **WIP STATUS** As of August 2024, functionality is being finalized (e.g. HoloViews [#6318](https://github.com/holoviz/holoviews/pull/6318) and a narrative workflow will be added soon. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add benchmarking summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "WIP. Coming soon - Summary of the benchmarking results and comparisons of the key workflow segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51323dc1-49b4-4c2f-ba8f-2cc2772ec795",
   "metadata": {},
   "source": [
    "# Time-Lapse Microscopy\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de380c6-9e2d-4d59-a8bf-2f9f2739cf23",
   "metadata": {},
   "source": [
    "<img \n",
    "    src=\"./assets/timelapse_header.png\" \n",
    "    alt=\"Time-Lapse Microscopy header\" \n",
    "    align=\"center\" \n",
    "    style=\"border: 2px solid #ccc; border-radius: 8px; padding: 5px; width: 100%; box-shadow: 0px 4px 8px rgba(0,0,0,0.1);\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe53a94-ddfd-474c-b802-832276a6c543",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center; padding: 10px;\">\n",
    "    <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Qa-wrIdMYH0?si=KDzApOEt2e4ROu-l\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f0bb6c-3cc7-430d-a1a5-e4cf4c0e51b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This workflow demonstrates the display of time-lapse microscopy in neuroscience. Each frame in the image-stack dataset corresponds to a concurrent time sample, typically intended to capture a dynamic process of living cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de8be5-81d9-4755-b7aa-afbacd5166e3",
   "metadata": {},
   "source": [
    "For example, a dynamic process of interest could be [neural action potentials](https://en.wikipedia.org/wiki/Action_potential), and the data might come from a [miniature microscope](http://miniscope.org/) (**see image in this notebook's header**) that captures the change in fluorescence of special proteins caused by electrochemical fluctuations indicative of neuronal activity. These video-like datasets often contain many more frames in the 'Time' dimension compared to the number of pixels in the height or width of each frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cdf8a0-63ad-478d-a6d2-2e8a283ed362",
   "metadata": {},
   "source": [
    "### App Versions\n",
    "We will build three different visualization approaches to cater to different use cases:\n",
    "\n",
    "1. **Basic Viewer:** A one-line application using [hvPlot](https://hvplot.holoviz.org/) for quick visualization of the image stack.\n",
    "2. **Intermediate Viewer with Side Views:** Uses [HoloViews](https://holoviews.org/) for additional interactive elements, scalebars, and linked side views, aiding better navigation of the image stack and identification of regions of interest.\n",
    "3. **Advanced Viewer with Annotations and Linked Timeseries:** Building from the intermediate `HoloViews` viewer, this version adds annotation capabilities using [HoloNote](https://holonote.holoviz.org/), allowing for interactive spatial annotations with linked timeseries.\n",
    "\n",
    "These applications are designed to handle large datasets efficiently, leveraging tools like `Xarray`, `Dask`, and `Zarr` for scalable data management.\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Basic Viewer:** Ideal for quick inspections and preliminary analyses of image stacks.\n",
    "- **Intermediate Viewer:** Provides enhanced navigation through the data with side views, useful for identifying regions of interest.\n",
    "- **Advanced Viewer:** Enables detailed analysis with spatial annotations and timeseries plots, suitable for in-depth studies of dynamic processes in microscopy data.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "| Topic | Type | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Xarray Tutorial](https://tutorial.xarray.dev/overview/xarray-in-45-min) | Prerequisite | Essential introduction to working with `xarray` data |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544217cf-1bd0-4d71-b6c6-9b3bf607d6f1",
   "metadata": {},
   "source": [
    "## Imports and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beec6d4-5948-4d16-a63e-d328fc6e6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import rasterize\n",
    "import hvplot.xarray # noqa\n",
    "import panel as pn\n",
    "import fsspec\n",
    "\n",
    "pn.extension('tabulator')\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182c860-0d3a-4d27-a07e-4a114ac4b6d7",
   "metadata": {},
   "source": [
    "## Loading and Inspecting the Data\n",
    "\n",
    "We'll be working with a sample dataset of time-lapse microscopy images. The dataset is stored in Zarr format, which is optimized for chunked, compressed, and scalable storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd039f-fb72-4dc5-bacf-72a3f4928a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'https://datasets.holoviz.org/miniscope/v1/real_miniscope_uint8.zarr/'\n",
    "DATA_DIR = Path('./data')\n",
    "DATA_FILENAME = Path(DATA_URL).name\n",
    "DATA_PATH = DATA_DIR / DATA_FILENAME\n",
    "\n",
    "print(f'Local Data Path: {DATA_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24df7408-30c1-4e32-8027-4d6bd46f55eb",
   "metadata": {},
   "source": [
    "Let's download the dataset (if it wasn't already) so we can have a local copy and avoid any network delays. However, this workflow should also work if the dataset stays remote (thanks to Xarray, Zarr, Dask, and other scalability-providing tools), such as when it's too large to reasonably download in its entirety.\n",
    "\n",
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Note</p>\n",
    "    If you are viewing this notebook as a result of using the `anaconda-project run` command, the data has already been ingested, as configured in the associated yaml file. Running the following cell should find that data and skip any further download.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19e87b-508f-4340-9445-8b4b8a0e6fdb",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-warning\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Warning</p>\n",
    "    If the data was not previously ingested with `anaconda-project`, the following cell will download ~300 MB the first time it is run.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa7ae8-35a9-43c4-a602-ec5fcf809f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the data if it doesn't exist\n",
    "if not DATA_PATH.exists():\n",
    "    print(f'Downloading data to: {DATA_PATH}')\n",
    "    ds_remote = xr.open_dataset(\n",
    "        fsspec.get_mapper(DATA_URL), engine='zarr', chunks={}\n",
    "    )\n",
    "    ds_remote.to_zarr(str(DATA_PATH))  # Save locally\n",
    "    print(f'Dataset downloaded to: {DATA_PATH}')\n",
    "else:\n",
    "    print(f'Data exists at: {DATA_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f2c9a-0f0e-418d-a4b5-d292239a608f",
   "metadata": {},
   "source": [
    "Now, let's load the dataset using `xarray`, specifying chunks for efficient data handling with `Dask`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d7a758-f56c-4954-85f1-db447e8144cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset from the local copy\n",
    "ds = xr.open_dataset(\n",
    "    DATA_PATH.as_posix(),\n",
    "    engine='zarr',\n",
    "    chunks={'frame': 400, 'height': -1, 'width': -1}  # Chunk by frames\n",
    ")\n",
    "\n",
    "# Access the variable 'varr_ref' which contains the image data\n",
    "da = ds['varr_ref']\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d259d0-3967-4389-a1c1-ca2bff622bfb",
   "metadata": {},
   "source": [
    "The dataset `da` is a 3D array with dimensions `(frame, height, width)`. Each frame corresponds to a time point in the image stack.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ad996b-abf5-4d8d-8b5c-2731b6436a7c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ada41-a3f9-4624-80e2-80a086d41d66",
   "metadata": {},
   "source": [
    "## App V1: Basic Viewer with hvPlot\n",
    "\n",
    "Our first application is a simple viewer using `hvPlot`, which allows for quick visualization of the image stack with minimal code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d583d-cce0-43f3-803d-ea1d755d16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvplot_app = da.hvplot.image(\n",
    "    groupby=\"frame\",\n",
    "    title='hvPlot App',\n",
    "    cmap='viridis',\n",
    "    clim=(0, 20),\n",
    "    aspect=da.sizes['width'] / da.sizes['height'],\n",
    "    widget_location='bottom',\n",
    ")\n",
    "hvplot_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07519ad4-98dc-4486-b551-bc96312b7115",
   "metadata": {},
   "source": [
    "As you can see, this creates an interactive image viewer where you can navigate through frames using a slider widget. Not much more needs to be said about that; it's simple and effective in a pinch! \n",
    "\n",
    "To easily enrich and extend this simple app, we do things like add a maximum-projection image so we can see the maximum fluorescence per pixel and visually locate the potential neurons in two-dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb3a4d-b53d-4cb1-a841-38fce3d6cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_proj = da.max('frame').compute().astype(np.float32)\n",
    "img_max_proj = max_proj.hvplot.image(\n",
    "    title='Max Over Time',\n",
    "    cmap=\"magma\",\n",
    "    clim=(0,20),\n",
    "    aspect=da.sizes['width'] / da.sizes['height']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760f25f-d185-42f5-9759-d50acc832d45",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Note</p>\n",
    "    Displaying the same interactive views or components across different cells in a notebook may lead to unintended consequences, as they are intentionally linked by default and can interfere. For this reason, many of the previews of the incremental steps in this tutorial are static previews.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ceacc-fb50-4c9d-ba3b-821c209ee9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pn.Row(hvplot_app, img_max_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccdeec0-1714-44c4-865c-c59bc038ef2a",
   "metadata": {},
   "source": [
    "<img \n",
    "    src=\"./assets/basic_max_app.png\"  \n",
    "    alt=\"Static Preview Basic app w Max\" \n",
    "    align=\"right\" \n",
    "    width=\"70%\">\n",
    "\n",
    "**Here's a static snapshot of what the previous cell produces - the basic app with a max projection over time. ðŸ‘‰**\n",
    "\n",
    "<div style=\"clear: both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c472854-1471-4192-a17d-e069fbdabf2d",
   "metadata": {},
   "source": [
    "This was a quick way to see one frame at a time! But it looks like there are a lot of fluorescent blobs (candidate neurons) in the 'Max Over Time' image and now we want a quick way to visually locate and navigate to the relevant frames in the image stack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a24ab-8ff1-4595-9246-54bc0afb03bf",
   "metadata": {},
   "source": [
    "## App V2: Intermediate Viewer with Side Views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e45d5d-af38-4538-be52-2304ed119012",
   "metadata": {},
   "source": [
    "As our data array is a three-dimensional volume, let's create a more advanced application using `HoloViews` in place of `hvPlot` to handle the added complexity, and `Panel` for more control over the layout and interactive links.\n",
    "\n",
    "This more advanced app builds on the previous one with added functionality, such as.\n",
    "\n",
    "1. **Side Views**: Aggregated side views for display over 'deep' time dimension.\n",
    "2. **Synchronized Frame Indicators**: Frame markers on the Side Views synchronized with the playback and x,y range of the main image stack view.\n",
    "4. **Slider Overlay Opacity**: Slider widget to adjust opacity of max-over-time overlay for direct comparison and a tighter layout.\n",
    "5. **Scale Bar**: A dynamic and customizable visual reference for spatial scale.\n",
    "3. **Continuous Playback**: Player widget for continuous playback, along with controls for step-by-step examination of the image stack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54065a9-9389-4c21-a020-743bdb3f2f0f",
   "metadata": {},
   "source": [
    "### Main Image and Playback Controls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a263ad4b-6eee-4399-9eb6-278d7cc12205",
   "metadata": {},
   "source": [
    "\n",
    "<img \n",
    "    src=\"./assets/int_app_main_w_player.png\"\n",
    "    alt=\"Static Preview Intermediate app Main w Player\" \n",
    "    align=\"right\"\n",
    "    width=70%\n",
    "    >\n",
    "\n",
    "**Here's a static snapshot of the main view and frame player that we'll make now. ðŸ‘‰**\n",
    "\n",
    "\n",
    "<div style=\"clear: both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd68bc1-d90c-4c34-a5dc-c6cf5781b5ab",
   "metadata": {},
   "source": [
    "First, we'll define a function to create the main image view for a given frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25fbda1-bf0a-47cd-8f21-8cbc9a095e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(frame):\n",
    "    return hv.Image(da.sel(frame=frame), kdims=[\"width\", \"height\"]).opts(\n",
    "        title=f'Frame = {frame}',\n",
    "        frame_height=da.sizes['height'],\n",
    "        frame_width=da.sizes['width'],\n",
    "        cmap='Viridis',\n",
    "        clim=(0, 20),\n",
    "        colorbar=True,\n",
    "        tools=['hover', 'crosshair'],\n",
    "        toolbar='right',\n",
    "        apply_hard_bounds=True,\n",
    "        scalebar=True,\n",
    "        scalebar_unit=(\"Âµm\", \"m\"),  # Each pixel is about 1 Âµm in this dataset\n",
    "        scalebar_opts={\n",
    "            'background_fill_alpha': 0.5,\n",
    "            'border_line_color': None,\n",
    "            'bar_length': 0.10,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8234ca53-d8f6-4d19-aed8-eee26893cdaa",
   "metadata": {},
   "source": [
    "We'll also create a `Player` widget to control frame playback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f2db8-ab17-409a-8c17-51f6cb67b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_player = pn.widgets.Player(\n",
    "    length=len(da.coords['frame']),\n",
    "    interval=100,  # Inter-frame-interval in milliseconds\n",
    "    value=20,     # Arbitrary starting frame\n",
    "    show_loop_controls=False,\n",
    "    align='center',\n",
    "    scale_buttons=0.9,\n",
    "    sizing_mode='stretch_width',\n",
    "    show_value=True,\n",
    "    value_align='center',\n",
    "    visible_buttons=['slower', 'previous', 'pause', 'play', 'next', 'faster'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a05ac-2f9e-466a-bbc0-81a1c124bd7f",
   "metadata": {},
   "source": [
    "We will `bind` (see [relevant Panel docs](https://panel.holoviz.org/explanation/api/reactivity.html)) the main frame-wise view to the player widget. Using [`DynamicMap`](https://holoviews.org/reference/containers/bokeh/DynamicMap.html), we ensure that only the plot contents are updated, maintaining the zoom level and other plot settings across updates. Additionally, by binding to [`value_throttled`](https://panel.holoviz.org/explanation/components/components_overview.html#throttling), we update the frame only when the user releases the slider, which improves performance by avoiding unnecessary updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf408d-77e4-4538-9359-6642b81e9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_view = hv.DynamicMap(pn.bind(plot_image, frame_player.param.value_throttled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6071e990-528f-41b7-8a46-ead6e982c13a",
   "metadata": {},
   "source": [
    "### Maximum Projection Overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982cf6de-e4ac-445b-8cf6-92de7f43c499",
   "metadata": {},
   "source": [
    "<img \n",
    "    src=\"./assets/int_app_max_w_slider.png\"  \n",
    "    alt=\"Static Preview Intermediate App Max Projection with Slider\" \n",
    "    align=\"right\" \n",
    "    width=\"70%\">\n",
    "\n",
    "**Here's a static snapshot of the max projection with a linked opacity slider that we'll make now. ðŸ‘‰**\n",
    "\n",
    "<div style=\"clear: both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a3dfb-9ec6-463b-b0ea-28b402515a16",
   "metadata": {},
   "source": [
    "We now create a max time-projected image and a slider widget to adjust the transparency of this overlay. As before, the max projection helps in identifying areas of interest by showing the maximum value over time for each pixel. We'll use a fast [`jslink`](https://panel.holoviz.org/how_to/links/jslinks.html) approach to link to the slider to the opacity parameter of the image since this is a simple visual property update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638284dd-fe86-4d41-be4c-ed28e3fc25af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the maximum projection over time\n",
    "max_proj_time = da.max('frame').compute().astype(np.float32)\n",
    "\n",
    "# Create the maximum projection image\n",
    "img_max_proj_time = hv.Image(\n",
    "    max_proj_time, ['width', 'height'], label='Max Over Time'\n",
    ").opts(\n",
    "    cmap='magma',\n",
    ")\n",
    "\n",
    "# Opacity slider for the overlay\n",
    "opacity_slider = pn.widgets.FloatSlider(\n",
    "    start=0, end=1, step=0.1, value=0.3, name='Opacity', align='center', sizing_mode='stretch_width'\n",
    ")\n",
    "\n",
    "# Link the slider value to the overlay's alpha (opacity)\n",
    "opacity_slider.jslink(img_max_proj_time, value='glyph.global_alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c63e21-8813-4fba-808c-77caf7c1d39b",
   "metadata": {},
   "source": [
    "### Side Views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6dc778-7205-4e96-a72f-0ea176909d97",
   "metadata": {},
   "source": [
    "<img \n",
    "    src=\"./assets/side_views.png\"  \n",
    "    alt=\"Static Preview Intermediate App Side Views\" \n",
    "    align=\"right\" \n",
    "    width=\"70%\">\n",
    "\n",
    "**Here's a static snapshot of the side views with a linked frame indicator lines that we'll make now. ðŸ‘‰**\n",
    "\n",
    "<div style=\"clear: both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6e114-d2dc-4ced-bac1-606fb802b5d9",
   "metadata": {},
   "source": [
    "To provide context over the time dimension, we'll add side views showing the mean intensity over time along the height and width dimensions.\n",
    "\n",
    "The right-side view (as if looking at our 3D volume from the right side) will be a frame-by-height view, and the top-side view will be a width-by-frame view. Using `.persist()` (see [relevant Xarray docs](https://docs.xarray.dev/en/stable/user-guide/dask.html#using-dask-with-xarray) allows us to cache the results of the mean calculations, reducing recomputation and improving performance. `Rasterizing` these views helps to limit the amount of data sent to the browser, ensuring efficient rendering (see [relevant HoloView's docs](https://holoviews.org/user_guide/Large_Data.html)). We will also set `axiswise=True` to prevent the side views from adjusting to the range of the main view, as we want them to be stable references of the full range on their respective axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c484578-1aac-4db4-9edd-9f5da94f2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for the side views\n",
    "side_view_opts = dict(\n",
    "    cmap='greys_r',\n",
    "    tools=['crosshair', 'hover'],\n",
    "    axiswise=True,\n",
    "    apply_hard_bounds=True,\n",
    "    colorbar=False,\n",
    "    toolbar=None,\n",
    ")\n",
    "\n",
    "side_view_width = 175\n",
    "\n",
    "# Top view: mean over height\n",
    "top_data = da.mean('height').persist()\n",
    "top_view = rasterize(\n",
    "    hv.Image(top_data, kdims=['width', 'frame']).opts(\n",
    "        frame_height=side_view_width,\n",
    "        frame_width=da.sizes['width'],\n",
    "        title='Top Side View',\n",
    "        xaxis='top',\n",
    "        **side_view_opts\n",
    "    )\n",
    ")\n",
    "\n",
    "# Right view: mean over width\n",
    "right_data = da.mean('width').persist()\n",
    "right_view = rasterize(\n",
    "    hv.Image(right_data, kdims=['frame', 'height']).opts(\n",
    "        frame_height=da.sizes['height'],\n",
    "        title='Right Side View',\n",
    "        yaxis='right',\n",
    "        frame_width=side_view_width,\n",
    "        **side_view_opts\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db9f3a79-841c-4ef5-a36c-5d63e179590d",
   "metadata": {},
   "source": [
    "We'll add indicators on the side views to show the current frame and the zoom range of the main view.\n",
    "\n",
    "First, the position of these lines indicates the current frame and is linked to the frame_player value. Instead of using throttled updates for the frame indicator lines, we `bind` directly to the unthrottled value of the frame player since this is a computationally inexpensive operation. This decision ensures that the frame indicators follow the slider in real time, providing a smooth and responsive user experience as the user scrubs through the frames. \n",
    "\n",
    "Second, the extents of the indicator lines adjust dynamically as the user interacts with the range (zoom, pan) in the main plot. To achieve this, we use a `streams.RangeXY` from HoloViews, which allows us to subscribe the indicator line extents to the range of the main view plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55634ee-fb7b-47fa-809a-2e8975a1f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hline(frame, x_range, y_range):\n",
    "    if x_range is None:\n",
    "        x_range = [int(da.width[0].values), int(da.width[-1].values)]\n",
    "    return hv.Segments((x_range[0], frame, x_range[1], frame)).opts(axiswise=True)\n",
    "\n",
    "def plot_vline(frame, x_range, y_range):\n",
    "    if y_range is None:\n",
    "        y_range = [int(da.height[0].values), int(da.height[-1].values)]\n",
    "    return hv.Segments((frame, y_range[0], frame, y_range[1])).opts(axiswise=True)\n",
    "\n",
    "line_opts = dict(color='red', line_width=3, line_alpha=0.4, line_dash='dashed')\n",
    "xyrange_stream = hv.streams.RangeXY(source=main_view)\n",
    "dmap_hline = hv.DynamicMap(pn.bind(plot_hline, frame_player), streams=[xyrange_stream]).opts(**line_opts, **side_view_opts)\n",
    "dmap_vline = hv.DynamicMap(pn.bind(plot_vline, frame_player), streams=[xyrange_stream]).opts(**line_opts, **side_view_opts)\n",
    "\n",
    "# Overlay the frame indicators on the side views\n",
    "top_view_overlay = (top_view * dmap_hline).opts(axiswise=True)\n",
    "right_view_overlay = (right_view * dmap_vline).opts(axiswise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8543009-0767-4aa7-8b19-0f4ba7258fcb",
   "metadata": {},
   "source": [
    "### Layout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b789b-d47e-4610-9ad2-e1bb08f84f8b",
   "metadata": {},
   "source": [
    "Now we'll assemble all components into a cohesive layout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc64d46-751f-4232-bf7c-4ad56d25fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the maximum projection on the main view\n",
    "main_view_overlay = main_view * img_max_proj_time\n",
    "\n",
    "# Arrange the main view and right side view horizontally\n",
    "main_and_right_layout = pn.Row(main_view_overlay, right_view_overlay)\n",
    "\n",
    "# Wrap the player and slider in collapsble Card widgets\n",
    "player_layout = pn.Card(\n",
    "    frame_player,\n",
    "    title='Playback',\n",
    "    sizing_mode='stretch_width',\n",
    "    margin=(0, 0, 20, 0),\n",
    ")\n",
    "\n",
    "opacity_slider_layout = pn.Card(\n",
    "    opacity_slider,\n",
    "    title='Max Projection Overlay',\n",
    "    sizing_mode='stretch_width',\n",
    "    margin=(0, 0, 20, 0),\n",
    ")\n",
    "\n",
    "# Combine the controls\n",
    "controls = pn.Column(\n",
    "    player_layout,\n",
    "    opacity_slider_layout,\n",
    "    align='center',\n",
    "    width=350,\n",
    ")\n",
    "\n",
    "# Assemble the full application layout\n",
    "intermediate_app = pn.Row(\n",
    "    controls,\n",
    "    pn.Column(\n",
    "        top_view_overlay,\n",
    "        main_and_right_layout,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e008d2-7f81-47f2-8d5e-8ac263e0bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intermediate_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef6faf-dd4d-409e-9dbd-11d6712227a2",
   "metadata": {},
   "source": [
    "<img \n",
    "    src=\"./assets/intermediate_app.png\" \n",
    "    alt=\"Static Preview Intermediate App\" \n",
    "    align=\"right\" \n",
    "    width=\"70%\">\n",
    "\n",
    "**Here's a static snapshot of what the previous cell produces - the intermediate app with side views and enhanced controls. ðŸ‘‰**\n",
    "\n",
    "<div style=\"clear: both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed876f2b-728f-46bc-8759-9e4166fb7c3e",
   "metadata": {},
   "source": [
    "## App V3: Advanced Viewer with Annotations and Timeseries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d52e0c-eac2-429d-8658-f8ad17c2cfb1",
   "metadata": {},
   "source": [
    "So far, our app allows us to navigate the image stack, but this is usually just the very start of the neuroscience investigation. From this imaging data, it's often essential to next derive a collection of timeseries traces that reflect when individual biological neurons are more or less active, as indicated by the change in image intensity within the spatial regions occupied by each neuron. \n",
    "\n",
    "Although there are automated approaches to aid in estimating the spatial outline of each cell, let's work out a complementary approach of how to manually specify and log particular spatial regions of interest using `HoloNote`. Linked to these annotated regions of interest, we can also set up a view that populates with the mean image intensity per frame to form the estimated neural activity fluctuations over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8a85b9-faf3-4042-bdd4-c2e359a289c1",
   "metadata": {},
   "source": [
    "### Setting Up the Annotator\n",
    "\n",
    "Now we'll configure the Annotator object from HoloNote, which manages the annotations and integrates them with our plots.\n",
    "\n",
    "In this demo, we're using a `connector` to an in-memory SQLite database by specifying `SQLiteDB(filename=':memory:')` for temporary storage of annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943145a0-0a98-48d5-b2e2-6a7e67d84b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from holonote.annotate import Annotator\n",
    "from holonote.app import PanelWidgets, AnnotatorTable\n",
    "from holonote.annotate.connector import SQLiteDB\n",
    "\n",
    "# Initialize the annotator for 'height' and 'width' dimensions\n",
    "annotator = Annotator(\n",
    "    {'height': float, 'width': float},\n",
    "    fields=['type'],  # Additional field to categorize annotations\n",
    "    groupby='type',   # Group annotations to enable color-coding and batch actions\n",
    "    connector=SQLiteDB(filename=':memory:'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7eb49e-4483-484b-b9f5-8680fb40ce05",
   "metadata": {},
   "source": [
    "**Note on Persistent Storage:** If we don't specify a connector, HoloNote will by default create a persistent SQLite database file named 'annotations.db' in the current directory. You can also specify a custom filename in place of `':memory:'` to store annotations persistently in a specific file, such as `SQLiteDB(filename='my_annotations.db')`.\n",
    "\n",
    "When working in a real workflow, you'll likely want persistent storage to save your annotations between sessions. Be aware that if a file with the specified name already exists, HoloNote will use it, and any changes committed through the UI will modify this file. This allows you to maintain and update your annotations across different sessions, ensuring your work is saved and accessible later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc9ddc-dd8c-41cd-97fd-b78dd4070ba4",
   "metadata": {},
   "source": [
    "Now we can optionally choose to add colors and styling to particular annotation types. For instance, maybe we want all of 'A'-labeled boxes to be red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ec78b-57b3-4c1c-b6fa-af04bcb45c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Define colors for annotation 'types' that we might expect to make\n",
    "color_dim = hv.dim('type').categorize(\n",
    "    categories={\n",
    "        'A': 'red',\n",
    "        'B': 'orange',\n",
    "        'C': 'cyan',\n",
    "    },\n",
    "    default='grey',\n",
    ")\n",
    "\n",
    "# Style the annotations\n",
    "annotator.style.color = color_dim # apply custom colors if we made them\n",
    "annotator.style.alpha = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ffc7c5-7ff5-40f5-9275-a0883096d9f1",
   "metadata": {},
   "source": [
    "### Configuring Annotation Widgets\n",
    "To enable interaction with the annotations, we'll create widgets that allow users to view and manage them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d5aa2-4c70-4caf-888d-72e7abd01be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annotation widgets\n",
    "panel_widgets = PanelWidgets(annotator)\n",
    "table_widget = AnnotatorTable(\n",
    "    annotator,\n",
    "    tabulator_kwargs={\n",
    "        'sizing_mode': 'stretch_width',\n",
    "        'theme': 'midnight',\n",
    "        'layout': 'fit_columns',\n",
    "        'sortable': False,\n",
    "        'stylesheets': [':host .tabulator {font-size: 9px;}'],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7e1e7-186b-4f79-9fc9-00bdb354ea43",
   "metadata": {},
   "source": [
    "The above code creates:\n",
    "- Annotation controls (PanelWidgets) for adding, editing, or deleting annotations. Since we grouped the annotations, `PanelWidgets` will also include a 'Visible' widget to toggle visibility by group.\n",
    "- An `AnnotatorTable` to display annotations in a tabular format.\n",
    "\n",
    "We also customize the table's appearance and functionality using `tabulator_kwargs`, adjusting pagination, sizing, layout, theme, style, and text alignment. Check our the [Panel Tabulator](https://panel.holoviz.org/reference/widgets/Tabulator.html) docs for more options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a553b-41e1-476d-8f58-845eb7398cf1",
   "metadata": {},
   "source": [
    "### Timeseries of Annotated Regions\n",
    "\n",
    "We'll create timeseries plots that show the mean intensity over time for each annotated region. We will connect the `.on_event` method of the `Annotator` to a `plot_ts` function that returns a subcoordinate timeseries plot of all the mean-aggregated spatial annotations per frame. We'll also add a vertical line to indicate the current frame, which we'll `bind` to our `frame_player` widget for updates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca92da-83b9-4598-8d2a-772431bd5c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for the timeseries plot\n",
    "curve_opts = dict(\n",
    "    height=300,\n",
    "    width=da.sizes['width'] + side_view_width + 225, # align to main_layout width\n",
    "    show_legend=False,\n",
    "    xlabel='Frame',\n",
    "    tools=['hover'],\n",
    "    line_alpha=0.5,\n",
    "    framewise=True,\n",
    "    axiswise=True,\n",
    ")\n",
    "\n",
    "# Options for the timeseries' frame indicator\n",
    "vline_opts = dict(color='grey', line_width=4, alpha=0.5)\n",
    "\n",
    "# Function to plot timeseries when annotations change\n",
    "def plot_ts(event):\n",
    "    curves = {}\n",
    "    df = annotator.df\n",
    "    for idx, row in df.iterrows():\n",
    "        h1, h2, w1, w2 = row[['start[height]', 'end[height]', 'start[width]', 'end[width]']]\n",
    "        da_sel = da.sel(height=slice(h1, h2), width=slice(w1, w2))\n",
    "        mean_ts = da_sel.mean(['height', 'width'])\n",
    "        group = f'G_{row[\"type\"]}'\n",
    "        label = f'L_{idx[:6]}'\n",
    "        curve = hv.Curve(mean_ts, group=group, label=label)\n",
    "        curve = curve.opts(\n",
    "            subcoordinate_y=True,\n",
    "            color=panel_widgets.colormap[row['type']],\n",
    "            **curve_opts,\n",
    "        )\n",
    "        curves[(group, label)] = curve\n",
    "    time_series.object = (vline * hv.Overlay(curves, kdims=['curve'])).opts(\n",
    "        hv.opts.Curve(xlim=(frames[0], frames[-1])),\n",
    "    )\n",
    "\n",
    "# Function to create a vertical line indicating the current frame\n",
    "def plot_frame_indicator_line(value):\n",
    "    if value:\n",
    "        return hv.VSpans((value, value)).opts(\n",
    "            axiswise=True, framewise=True, **vline_opts\n",
    "        )\n",
    "\n",
    "# Get the range of frames\n",
    "frames = da.coords['frame'].values\n",
    "\n",
    "# Create a DynamicMap for the frame indicator line\n",
    "vline = hv.DynamicMap(pn.bind(plot_frame_indicator_line, frame_player)).opts(\n",
    "    hv.opts.VLine(**vline_opts)\n",
    ")\n",
    "\n",
    "# Initialize the timeseries pane\n",
    "time_series = pn.pane.HoloViews(\n",
    "    vline * hv.Curve([]).opts(\n",
    "        xlim=(frames[0], frames[-1]),\n",
    "        title='Create an annotation in the image',\n",
    "        **curve_opts,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Connect the annotation events to the plotting function\n",
    "annotator.on_event(plot_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21834945-b33c-4dff-94e0-056b6ed9dcae",
   "metadata": {},
   "source": [
    "### Defining Annotations\n",
    "\n",
    "Optionally, if we have some pre-existing annotations, we can add to the annotation database. If you started without any existing annotations, you can skip this step, and the Annotator will start without any entries, ready for you to add new ones interactively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a8455-9b71-4842-8444-251033cf0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.DataFrame(\n",
    "    [[430, 480, 80, 130, 'A']],\n",
    "    columns=['x1', 'x2', 'y1', 'y2', 'type']\n",
    ")\n",
    "annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c02f7-f34d-4ef5-8431-077a87fb313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator.define_annotations(\n",
    "    annotations_df,\n",
    "    width=(\"x1\", \"x2\"),\n",
    "    height=(\"y1\", \"y2\"),\n",
    "    type='type',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a683fb-8890-4134-a42a-838b0d9f064e",
   "metadata": {},
   "source": [
    "### Updating the Layout\n",
    "\n",
    "We'll update the application layout from the intermediate app version to include the `annotator`, along with the associated widgets and timeseries plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc370d-9ced-4c95-b490-05296227c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the annotator on the main view\n",
    "main_view_overlay_anno = (main_view_overlay * annotator).opts(axiswise=True)\n",
    "# Overlay the annotator on the side views\n",
    "top_view_overlay_anno = (top_view_overlay * annotator).opts(axiswise=True)\n",
    "right_view_overlay_anno = (right_view_overlay * annotator).opts(axiswise=True)\n",
    "\n",
    "# Combine annotation controls and table into a Card\n",
    "annotator_widgets = pn.Card(\n",
    "    pn.Column(panel_widgets, table_widget),\n",
    "    title='Annotator',\n",
    "    sizing_mode='stretch_width',\n",
    "    margin=(0, 0, 20, 0),\n",
    "    collapsed=False,\n",
    ")\n",
    "\n",
    "# Add the annotator widgets to the controls\n",
    "controls.append(annotator_widgets)\n",
    "\n",
    "# Create the main content layout\n",
    "main_layout_anno = pn.Column(\n",
    "    top_view_overlay_anno,\n",
    "    pn.Row(main_view_overlay_anno, right_view_overlay_anno),\n",
    "    time_series,\n",
    ")\n",
    "\n",
    "# Assemble the final application layout\n",
    "advanced_app = pn.Row(\n",
    "    controls,      # Controls on the left\n",
    "    main_layout_anno,   # Main content on the right\n",
    "    align='start',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9be02-0915-4841-bf21-1ad3b69a4045",
   "metadata": {},
   "source": [
    "### Working with Annotations\n",
    "\n",
    "This [video preview](https://www.youtube.com/embed/Qa-wrIdMYH0?si=KDzApOEt2e4ROu-l) is a great way to see how an annotation is created with the HoloNote controls.\n",
    "\n",
    "How to add new annotations: \n",
    "1. Ensure that 'Box select (x-axis)' is selected in the Bokeh Toolbar on the right of the main frame plot.\n",
    "2. Ensure that the '+' button is selected in the Annotation widgets on the very left.\n",
    "3. Select a spatial range by clicking and dragging on the main frame plot.\n",
    "4. Enter the name of the group that you want the annotation to be added to in the 'type' text box.\n",
    "5. Edit or delete annotations using the provided widgets and table.\n",
    "6. If you are using a persistent file on disk for the annotations and are ready to commit, hit the triangle button in the Annotation widgets to commit changes to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319bba2f-4ff8-40b9-b953-2cf165f6e0f9",
   "metadata": {},
   "source": [
    "<img  \n",
    "    src=\"./assets/advanced_app_nb_steps.png\" \n",
    "    alt=\"Static Preview Advanced App in Notebook\" \n",
    "    align=\"right\" \n",
    "    width=\"80%\">\n",
    "\n",
    "**Here's a static snapshot of what the advanced app looks like in the notebook, after creating a box in the main view and assigning it a type in the annotation widget. ðŸ‘‰**\n",
    "\n",
    "<div style=\"clear: both;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd430c19-2754-4c0e-baad-932c82e25eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a840f75-817d-481c-a25a-c83ce60c0efa",
   "metadata": {},
   "source": [
    "## Standalone App Extension\n",
    "\n",
    "HoloViz Panel allows for the deployment of this complex visualization as a standalone, template-styled, interactive web application (outside of a Jupyter Notebook). Read more about Panel [here](https://panel.holoviz.org/).\n",
    "\n",
    "We'll add our plots to the `main` area of a Panel Template component and the widget-controls to the `sidebar`. Finally, we'll set the entire component to be `servable`.\n",
    "\n",
    "To launch the standalone app, activate the same conda environment and run `panel serve <path-to-this-file> --show` in the command line to open the application in a browser window (tip: use the `--dev` flag to auto update the app when the file changes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b10cd65-cbca-451a-9d07-3250034ca93a",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-warning\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Warning</p>\n",
    "    It is not recommended to have both a notebook version of the app and the served version of the same application running simultaneously. Prior to serving the standalone application, clear the notebook output, restart the notebook kernel, and save the unexecuted notebook file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15f4fa-c8a7-43f8-88f9-fba00f3d704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "servable_app = pn.template.FastListTemplate(\n",
    "    sidebar = controls,\n",
    "    title = \"HoloViz + Bokeh Time-Lapse Microscopy with Annotation\",\n",
    "    main = main_layout_anno,\n",
    "    main_layout=None,\n",
    "    sidebar_width=350,\n",
    "    theme=\"dark\",\n",
    "    accent=\"#30023f\"\n",
    ").servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585095bc-2402-4549-ac17-a1bf55e1faa2",
   "metadata": {},
   "source": [
    "## Copyable V3 App Code\n",
    "\n",
    "<details><summary> Expand to reveal </summary>\n",
    "\n",
    "```python\n",
    "print('TODO once the the notebook is reviewed')\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19384ef9-5d8c-44f6-8f0b-3267b2bb2329",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Experiment with your own datasets, extending the applications with additional features as needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "| What? | Why? |\n",
    "| --- | --- |\n",
    "| [Minian Repository](https://github.com/denisecailab/minian) | Analysis pipeline and visualization tool for Miniscope data |\n",
    "| [Miniscope Wiki](http://miniscope.org/index.php/Main_Page) | Further context for the demo application |\n",
    "| [HoloNote](https://holonote.holoviz.org/) | HoloNote package for annotation capabilities in HoloViz applications |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb106033-6d43-4e5e-9185-344cdb738c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

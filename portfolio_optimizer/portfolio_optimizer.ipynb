{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portfolio Optimization helps risk-averse investors construct portfolios to maximize expected return given a certain level of market risk, emphasizing the inherent relationship between risk and reward. We will begin by running an example of the Monte Carlo Simulation for an optimal portfolio with resulting returns. Then we will create an Efficient Frontier which is used to identify a set of optimal portfolios that offers the highest expected return for a defined level of risk or the lowest risk for a given level of expected return. This will be done using hvPlot and HoloViz which will allow users to visualize the trade-offs between risk and return. Lastly, we will combine all our analysis into a Panel app that enables users to dynamically explore the Efficient Frontier, adjust parameters, and visualize the resulting portfolios, streamlining the portfolio optimization process.\n",
    "\n",
    "We will be using a variety of HoloViz tools to support portfolio optimization analysis:\n",
    "- [hvPlot](https://hvplot.holoviz.org/) - generates visualizations such as line graphs and histograms from Pandas' data\n",
    "- [HoloViews](https://holoviews.org/) - creates the efficent frontier curve after the portfolio is optimized\n",
    "- [Panel](https://panel.holoviz.org/) - combines all the visualizations and graphs into a single interactive app\n",
    "  \n",
    "![image.png](dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Simulation for Optimization Search\n",
    "\n",
    "\n",
    "Monte Carlo simulations are used by analyst to determine the expected value and optimal distribution of a portfolio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas  # noqa\n",
    "import panel as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv('./data/stocks.csv', index_col='Date', parse_dates=True)\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_daily_ret = stocks.pct_change(1).mean()\n",
    "mean_daily_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.pct_change(1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Thousands of Possible Allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_normed = stocks/stocks.iloc[0]\n",
    "timeseries = stock_normed.hvplot()\n",
    "timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_daily_ret = stocks.pct_change(1)\n",
    "stock_daily_ret.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Returns vs Arithmetic Returns\n",
    "\n",
    "We will now switch over to using log returns instead of arithmetic returns, for many of our use cases they are almost the same,but most technical analyses require detrending/normalizing the time series and using log returns is a nice way to do that.\n",
    "Log returns are convenient to work with in many of the algorithms we will encounter.\n",
    "\n",
    "For a full analysis of why we use log returns, check [this great article](https://quantivity.wordpress.com/2011/02/21/why-log-returns/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret = np.log(stocks/stocks.shift(1))\n",
    "log_ret.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret_hists = log_ret.hvplot.hist(bins=100, subplots=True, width=400, \\\n",
    "    group_label='Ticker', grid=True).cols(2)\n",
    "log_ret_hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be multiplying the `log_ret.mean()` by 252 because there 252 trading days in a year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret.mean() * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise covariance of columns\n",
    "log_ret.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret.cov()*252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Run for Some Random Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed (optional)\n",
    "np.random.seed(101)\n",
    "\n",
    "# Stock Columns\n",
    "print('Stocks')\n",
    "print(stocks.columns)\n",
    "print('\\n')\n",
    "\n",
    "# Create Random Weights\n",
    "print('Creating Random Weights')\n",
    "weights = np.array(np.random.random(4))\n",
    "print(weights)\n",
    "print('\\n')\n",
    "\n",
    "# Rebalance Weights\n",
    "print('Rebalance to sum to 1.0')\n",
    "weights = weights / np.sum(weights)\n",
    "print(weights)\n",
    "print('\\n')\n",
    "\n",
    "# Expected Return\n",
    "print('Expected Portfolio Return')\n",
    "exp_ret = np.sum(log_ret.mean() * weights) *252\n",
    "print(exp_ret)\n",
    "print('\\n')\n",
    "\n",
    "# Expected Variance\n",
    "print('Expected Volatility')\n",
    "exp_vol = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov() * 252, weights)))\n",
    "print(exp_vol)\n",
    "print('\\n')\n",
    "\n",
    "# Sharpe Ratio\n",
    "SR = exp_ret/exp_vol\n",
    "print('Sharpe Ratio')\n",
    "print(SR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we can just run this many times over!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ports = 15000\n",
    "\n",
    "all_weights = np.zeros((num_ports,len(stocks.columns)))\n",
    "ret_arr = np.zeros(num_ports)\n",
    "vol_arr = np.zeros(num_ports)\n",
    "sharpe_arr = np.zeros(num_ports)\n",
    "\n",
    "for ind in range(num_ports):\n",
    "\n",
    "    # Create Random Weights\n",
    "    weights = np.array(np.random.random(4))\n",
    "\n",
    "    # Rebalance Weights\n",
    "    weights = weights / np.sum(weights)\n",
    "    \n",
    "    # Save Weights\n",
    "    all_weights[ind,:] = weights\n",
    "\n",
    "    # Expected Return\n",
    "    ret_arr[ind] = np.sum((log_ret.mean() * weights) *252)\n",
    "\n",
    "    # Expected Variance\n",
    "    vol_arr[ind] = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov() * 252, weights)))\n",
    "\n",
    "    # Sharpe Ratio\n",
    "    sharpe_arr[ind] = ret_arr[ind]/vol_arr[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_arr.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights[1419,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sr_ret = ret_arr[1419]\n",
    "max_sr_vol = vol_arr[1419]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = hv.Scatter((vol_arr, ret_arr, sharpe_arr), 'Volatility', ['Return', 'Sharpe Ratio'])\n",
    "max_sharpe = hv.Scatter([(max_sr_vol,max_sr_ret)])\n",
    "\n",
    "scatter.opts(color='Sharpe Ratio', cmap='plasma', width=600, height=400, colorbar=True, padding=0.1) *\\\n",
    "max_sharpe.opts(color='red', line_color='black', size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Optimization\n",
    "\n",
    "There are much better ways to find good allocation weights than just guess and check! We can use optimization functions to find the ideal weights mathematically!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Return and SR operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ret_vol_sr(weights):\n",
    "    \"\"\"\n",
    "    Takes in weights, returns array or return,volatility, sharpe ratio\n",
    "    \"\"\"\n",
    "    weights = np.array(weights)\n",
    "    ret = np.sum(log_ret.mean() * weights) * 252\n",
    "    vol = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov() * 252, weights)))\n",
    "    sr = ret/vol\n",
    "    return np.array([ret,vol,sr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fully understand all the parameters, check out the [`scipy.optimize.minimize` documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(minimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization works as a minimization function, since we actually want to maximize the Sharpe Ratio, we will need to turn it negative so we can minimize the negative sharpe (same as maximizing the postive sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_sharpe(weights):\n",
    "    return  get_ret_vol_sr(weights)[2] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contraints\n",
    "def check_sum(weights):\n",
    "    '''\n",
    "    Returns 0 if sum of weights is 1.0\n",
    "    '''\n",
    "    return np.sum(weights) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By convention of minimize function it should be a function that returns zero for conditions\n",
    "cons = ({'type':'eq','fun': check_sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-1 bounds for each weight\n",
    "bounds = ((0, 1), (0, 1), (0, 1), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Guess (equal distribution)\n",
    "init_guess = [0.25,0.25,0.25,0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Least SQuares Programming (SLSQP).\n",
    "opt_results = minimize(neg_sharpe,init_guess,method='SLSQP',bounds=bounds,constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ret_vol_sr(opt_results.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Optimal Portfolios (Efficient Frontier)\n",
    "\n",
    "The [efficient frontier](https://www.investopedia.com/terms/e/efficientfrontier.asp) is the set of optimal portfolios that offers the highest expected return for a defined level of risk or the lowest risk for a given level of expected return. Portfolios that lie below the efficient frontier are sub-optimal, because they do not provide enough return for the level of risk. Portfolios that cluster to the right of the efficient frontier are also sub-optimal, because they have a higher level of risk for the defined rate of return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our returns go from 0 to somewhere along 0.3\n",
    "# Create a linspace number of points to calculate x on\n",
    "frontier_y = np.linspace(0,0.3,100) # Change 100 to a lower number for slower computers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_volatility(weights):\n",
    "    return  get_ret_vol_sr(weights)[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_volatility = []\n",
    "\n",
    "for possible_return in frontier_y:\n",
    "    # function for return\n",
    "    cons = ({'type':'eq','fun': check_sum},\n",
    "            {'type':'eq','fun': lambda w: get_ret_vol_sr(w)[0] - possible_return})\n",
    "    \n",
    "    result = minimize(minimize_volatility,init_guess,method='SLSQP',bounds=bounds,constraints=cons)\n",
    "    \n",
    "    frontier_volatility.append(result['fun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_graph = scatter * hv.Curve((frontier_volatility, frontier_y)).opts(color='green', line_dash='dashed')\n",
    "ef_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a graph of the efficient frontier, let's take this a step further by building a Panel app around it. The app will allow a user to upload their own CSV of stock time series which will be analyzed to create a variety of graphs including the efficient frontier. We'll begin by first creating the sidebar for user input by using the `FileInput`, `IntSlider`, and `Button` widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension('tabulator', design='material', template='material', theme_toggle=True, loading_indicator=True)\n",
    "file_input = pn.widgets.FileInput(sizing_mode='stretch_width')\n",
    "selector = pn.widgets.MultiSelect(\n",
    "    name='Select stocks', sizing_mode='stretch_width',\n",
    "    options=stocks.columns.to_list()\n",
    ")\n",
    "\n",
    "\n",
    "n_samples = pn.widgets.IntSlider(\n",
    "    name='Random samples', value=10_000, start=1000, end=20_000, step=1000, sizing_mode='stretch_width'\n",
    ")\n",
    "button = pn.widgets.Button(name='Run Analysis', sizing_mode='stretch_width')\n",
    "posxy = hv.streams.Tap(x=None, y=None)\n",
    "\n",
    "text = \"\"\"\n",
    "#  Portfolio optimization\n",
    "\n",
    "This application performs portfolio optimization given a set of stock time series.\n",
    "\n",
    "To optimize your portfolio:\n",
    "\n",
    "1. Upload a CSV of the daily stock time series for the stocks you are considering\n",
    "2. Select the stocks to be included.\n",
    "3. Run the Analysis\n",
    "4. Click on the Return/Volatility plot to select the desired risk/reward profile\n",
    "\n",
    "Upload a CSV containing stock data:\n",
    "\"\"\"\n",
    "\n",
    "explanation = \"\"\"\n",
    "The code for this app was taken from [this excellent introduction to Python for Finance](https://github.com/PrateekKumarSingh/Python/tree/master/Python%20for%20Finance/Python-for-Finance-Repo-master).\n",
    "To learn some of the background and theory about portfolio optimization see [this notebook](https://github.com/PrateekKumarSingh/Python/blob/master/Python%20for%20Finance/Python-for-Finance-Repo-master/09-Python-Finance-Fundamentals/02-Portfolio-Optimization.ipynb).\n",
    "\"\"\"\n",
    "\n",
    "sidebar = pn.layout.WidgetBox(\n",
    "    pn.pane.Markdown(text, margin=(0, 10)),\n",
    "    file_input,\n",
    "    selector,\n",
    "    n_samples,\n",
    "    explanation,\n",
    "    max_width=350,\n",
    "    sizing_mode='stretch_width'\n",
    ").servable(area='sidebar')\n",
    "\n",
    "sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the sidebar component, we will create a function to read the inputted file. We will also use the `MultiSelect` widget to allow the user to select only certain stocks to be included in the portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pn.cache\n",
    "def get_stocks(data):\n",
    "    if data is None:\n",
    "        stock_file = 'https://datasets.holoviz.org/stocks/v1/stocks.csv'\n",
    "    else:\n",
    "        stock_file = BytesIO(data)\n",
    "    return pd.read_csv(stock_file, index_col='Date', parse_dates=True)\n",
    "\n",
    "\n",
    "file_input = pn.widgets.FileInput(sizing_mode='stretch_width')\n",
    "\n",
    "stocks = hvplot.bind(get_stocks, file_input).interactive()\n",
    "stocks = pn.rx(get_stocks)(file_input)\n",
    "\n",
    "selector = pn.widgets.MultiSelect(\n",
    "    name='Select stocks', sizing_mode='stretch_width',\n",
    "    options=stocks.columns.to_list()\n",
    ")\n",
    "\n",
    "selected_stocks = stocks.rx.pipe(\n",
    "    lambda df, cols: df[cols] if cols else df, selector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will define a variety of analytical functions to help us find the optimal portfolio allocation point on the efficient frontier visualization. The compute_frontier() function computes the efficient frontier using numerical optimization to find the minimum volatility portfolio for a range of expected returns. The find_best_allocation() function finds the optimal portfolio allocation that achieves the desired volatility and return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sum(weights):\n",
    "    return np.sum(weights) - 1\n",
    "\n",
    "def get_return(mean_ret, weights):\n",
    "    return np.sum(mean_ret * weights) * 252\n",
    "\n",
    "def get_volatility(log_ret, weights):\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(np.cov(log_ret[1:], rowvar=False) * 252, weights)))\n",
    "\n",
    "def minimize_difference(weights, des_vol, des_ret, log_ret, mean_ret):\n",
    "    ret = get_return(mean_ret, weights)\n",
    "    vol = get_volatility(log_ret, weights)\n",
    "    return abs(des_ret-ret) + abs(des_vol-vol)\n",
    "\n",
    "@pn.cache\n",
    "def find_best_allocation(log_return, vol, ret):\n",
    "    cols = log_return.shape[1]\n",
    "    vol = vol or 0\n",
    "    ret = ret or 0\n",
    "    mean_return = np.nanmean(log_return, axis=0)\n",
    "    bounds = tuple((0, 1) for i in range(cols))\n",
    "    init_guess = [1./cols for i in range(cols)]\n",
    "    cons = (\n",
    "        {'type':'eq','fun': check_sum},\n",
    "        {'type':'eq','fun': lambda w: get_return(mean_return, w) - ret},\n",
    "        {'type':'eq','fun': lambda w: get_volatility(log_return, w) - vol}\n",
    "    )\n",
    "    opt = minimize(\n",
    "        minimize_difference, init_guess, args=(vol, ret, log_return, mean_return),\n",
    "        bounds=bounds, constraints=cons\n",
    "    )\n",
    "    ret = get_return(mean_return, opt.x)\n",
    "    vol = get_volatility(log_return, opt.x)\n",
    "    return pd.Series(list(opt.x)+[ret, vol], index=list(log_return.columns)+['Return', 'Volatility'], name='Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions above, we find our optimal portfolio allocation point and overlay this on our efficient frontier graph. We also use the Tabulator widget to create a summary of the weights of stocks in our optimal portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data pipelines\n",
    "\n",
    "log_return = np.log(selected_stocks/selected_stocks.shift(1))\n",
    "selected_stocks = stocks\n",
    "closest_allocation = log_return.pipe(find_best_allocation, posxy.param.x, posxy.param.y)\n",
    "\n",
    "opts = {'x': 'Volatility', 'y': 'Return', 'responsive': True}\n",
    "\n",
    "closest_point = closest_allocation.to_frame().T.hvplot.scatter(color='green', line_color='black', size=50, **opts)\n",
    "\n",
    "ef_graph = ef_graph * closest_point * max_sharpe\n",
    "\n",
    "summary = pn.pane.Markdown(\n",
    "    pn.bind(lambda p: f\"\"\"\n",
    "    The selected portfolio has a volatility of {p.Volatility:.2f}, a return of {p.Return:.2f}\n",
    "    and Sharpe ratio of {p.Return/p.Volatility:.2f}.\"\"\", closest_allocation), width=250\n",
    ")\n",
    "\n",
    "table = pn.widgets.Tabulator(closest_allocation.to_frame().iloc[:-2])\n",
    "pn.Row(ef_graph, pn.Column(summary, table), sizing_mode='stretch_both')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also create a line graph that will help us visualize the performance of our portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment = pn.widgets.Spinner(name='Investment Value in $', value=5000, step=1000, start=1000, end=100000)\n",
    "year = pn.widgets.DateRangeSlider(name='Year', value=(stocks.index.rx.value.min(), stocks.index.rx.value.max()), \\\n",
    "                                  start=stocks.index.min(), end=stocks.index.max())\n",
    "\n",
    "def plot_performance(value_start, value_end, investment=investment.value):\n",
    "    allocation = closest_allocation.iloc[:-2] * investment\n",
    "    stocks_between_dates = selected_stocks.loc[value_start:value_end]\n",
    "    price_on_start_date = selected_stocks.loc[value_start].iloc[0]\n",
    "    plot = (stocks_between_dates * allocation / price_on_start_date).sum(axis=1).hvplot.line(\n",
    "        ylabel='Total Value ($)', title='Portfolio performance', responsive=True, min_height=400)\n",
    "    return plot\n",
    "\n",
    "performance_plot = pn.bind(plot_performance, year.param.value_start, year.param.value_end, investment)\n",
    "\n",
    "performance = pn.Column(\n",
    "    performance_plot,\n",
    "    sizing_mode='stretch_both'\n",
    ")\n",
    "\n",
    "pn.Row(pn.Column(year, investment), performan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take advantage of `pn.Tabs` which allows us to put all the graphs we have created into one app very neatly. Wow, we just created an interactive report by just using Holoviews, hvPlot, and Panel! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pn.Tabs(\n",
    "    ('Analysis', pn.Column(\n",
    "            pn.Row(\n",
    "                ef_graph, pn.Column(summary, table),\n",
    "                sizing_mode='stretch_both'\n",
    "            ),\n",
    "            performance,\n",
    "            sizing_mode='stretch_both'\n",
    "        )\n",
    "    ),\n",
    "    ('Timeseries', timeseries),\n",
    "    ('Log Return', pn.Column(\n",
    "        '## Daily normalized log returns',\n",
    "        'Width of distribution indicates volatility and center of distribution the mean daily return.',\n",
    "        log_ret_hists,\n",
    "        sizing_mode='stretch_both'\n",
    "    )),\n",
    "    sizing_mode='stretch_both', min_height=1000\n",
    ")\n",
    "\n",
    "pn.Row(sidebar, main).servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion with Panel UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion#:~:text=Stable%20Diffusion%20is%20a%20deep,guided%20by%20a%20text%20prompt) is a deep learning model released in 2022. Stable Diffusion can generate detailed, realistic images from text descriptions of what the image should contain or how it should appear. \n",
    "\n",
    "This example demonstrates how to use [Panel](https://panel.holoviz.org) to create a web browser application for running the [Diffusers library](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb), using pre-trained models from the runwayml and CompVis repositories. See [Diffusers on github](https://github.com/huggingface/diffusers#stable-diffusion-is-fully-compatible-with-diffusers) or the blogpost on [Stable Diffusion with Diffusers](https://huggingface.co/blog/stable_diffusion) for more details on the algorithm and the training set.\n",
    "\n",
    "## TL;DR\n",
    "\n",
    "This app should generate images in seconds on a system with a supported GPU, or in minutes on a CPU. It has been tested for deployment on osx-M1 with its integrated GPU, linux-64 with Nvidia GPUs (Quadro RTX 8000) installed, and linux-64 with only a CPU (no GPU; much slower). \n",
    "\n",
    "The app downloads two models from huggingface to `~/.cache/huggingface`, which take up ~ 17GB of disk space. You can run the code as a notebook or as a deployed dashboard/app if you first install anaconda-project and then run the appropriate command for your system:\n",
    "\n",
    "```\n",
    "# run notebook on linux-64 system\n",
    "anaconda-project run \n",
    "\n",
    "# run notebook on OSX-M1 system\n",
    "anaconda-project run notebook-m1\n",
    "\n",
    "# run panel dashboard app on linux-64 system\n",
    "anaconda-project run dashboard\n",
    "\n",
    "# run panel dashboard app on OSX-M1 system\n",
    "anaconda-project run dashboard-m1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.resources import INLINE\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook(resources=INLINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "@contextmanager\n",
    "def exec_time(description=\"Task\"):\n",
    "    \"\"\"Context manager to measure execution time and print it to the console\"\"\" \n",
    "    st = time.perf_counter()\n",
    "    yield \n",
    "    print(f\"{description}: {time.perf_counter() - st:.2f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking Stable Diffusion on a prompt\n",
    "\n",
    "The `init_model` function below will first look in the default cache location used by huggingface to find downloaded pretrained models. If these haven't been downloaded yet, it will first download the models. On subsequent restarts of the app, it will load the models from the local disk cache. \n",
    "\n",
    "<p>\n",
    "<details><summary><u>(Optional: how to download models manually)</u></summary>\n",
    "<pre>\n",
    "  pipe, cache = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", return_cached_folder=True, local_files_only=False)\n",
    "  pipe, cache = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\",  return_cached_folder=True, local_files_only=False)\n",
    "  print(cache) # to see the default cache location\n",
    "</pre>\n",
    "</details>\n",
    "\n",
    "In addition to caching the pretrained model, we also initialize and cache the in-memory diffusers pipeline inside `panel.state.cache`. This ensures that each new visitor to the page does not load the same model into memory again.\n",
    "\n",
    "The initial page load takes an extra ~10 sec or so (on a Quadro RTX 8000) and allocates the GPU memory required to load the pipeline in memory. Subsequent visitors get this pipeline from panel's cache. The memory overhead per visitor is then the amount needed to generate the image text prompt.\n",
    "\n",
    "<details><summary><p><br><u>(Optional: performance details)</u></summary>\n",
    "    \n",
    "Sample output from `nvidia-smi` with memory usage information, running on a machine with Quadro RTX 8000 GPUs, after both models load:\n",
    "\n",
    "<pre>\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Quadro RTX 8000     Off  | 00000000:15:00.0 Off |                  Off |\n",
    "| 33%   33C    P8    24W / 260W |     48MiB / 49152MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  Quadro RTX 8000     Off  | 00000000:2D:00.0 Off |                  Off |\n",
    "| 33%   40C    P8    29W / 260W |   5933MiB / 49152MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "\n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|    0   N/A  N/A      2024      G   /usr/lib/xorg/Xorg                 23MiB |\n",
    "|    0   N/A  N/A      2545      G   /usr/bin/gnome-shell               20MiB |\n",
    "|    1   N/A  N/A      2024      G   /usr/lib/xorg/Xorg                  4MiB |\n",
    "|    1   N/A  N/A   2263594      C   .../diffusers/bin/python3.11     5925MiB |\n",
    "+-----------------------------------------------------------------------------+\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_int_range = 1, int(1e6)\n",
    "\n",
    "def init_model(model, cuda, mps, local_files_only=True):\n",
    "    print(f\"Init model: {model}\")\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model,\n",
    "        torch_dtype=torch.float16 if cuda or mps else None,\n",
    "        local_files_only=local_files_only)        \n",
    "\n",
    "    # let torch choose the GPU if more than 1 is available\n",
    "    if cuda:\n",
    "        pipe.to(f\"cuda\")\n",
    "    elif mps:\n",
    "        pipe.to(f\"mps\")\n",
    "        pipe.enable_attention_slicing()\n",
    "    return pipe     \n",
    "\n",
    "\n",
    "if 'pipelines' in pn.state.cache:\n",
    "    print(f\"load from cache\")\n",
    "    pipelines = pn.state.cache['pipelines']\n",
    "    pseudo_rand_gen = pn.state.cache['pseudo_rand_gen']\n",
    "else:\n",
    "    cuda = torch.cuda.is_available()\n",
    "    mps  = torch.backends.mps.is_available()\n",
    "    device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "    models = ['runwayml/stable-diffusion-v1-5', \n",
    "              'CompVis/stable-diffusion-v1-4']\n",
    "    \n",
    "    pseudo_rand_gen = torch.Generator(device=device)\n",
    "    with exec_time(\"Load models\"):\n",
    "        pipelines = dict()\n",
    "        for m in models:\n",
    "            try:\n",
    "                # try to load files from cache first\n",
    "                pipelines[m] = init_model(m, cuda, mps)\n",
    "            except OSError:\n",
    "                pipelines[m] = init_model(m, cuda, mps, local_files_only=False)\n",
    "            \n",
    "    pn.state.cache['pipelines'] = pipelines\n",
    "    pn.state.cache['pseudo_rand_gen'] = pseudo_rand_gen\n",
    "    print(f\"Save to cache\")\n",
    "\n",
    "\n",
    "default_model = next(iter(pipelines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model, we can invoke it to generate an output (uncomment if needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines[default_model](prompt=\"Chair made from twisted vines, in a manicured garden\",\n",
    "#                         generator=pseudo_rand_gen.manual_seed(5))[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaner interface, with parameters\n",
    "\n",
    "That's pretty awkward to run, so let's use [Param](param.holoviz.org) to document what the user parameters are and provide a cleaner interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import param\n",
    "\n",
    "class StableDiffusion(param.Parameterized):\n",
    "    prompt = param.String(doc=\"\"\"\n",
    "        Text describing the image you wish to generate\"\"\")\n",
    "    \n",
    "    negative_prompt = param.String(doc=\"\"\"\n",
    "        Text describing what _not_ to include in the image (for refining results)\"\"\")\n",
    "    \n",
    "    model = param.Selector(objects=list(pipelines), default=default_model, doc=\"\"\"\n",
    "        A pre-trained model to be used for inference\"\"\")\n",
    "    \n",
    "    _size_range = tuple(448 + i*2**6 for i in range(10))\n",
    "    width = param.Selector(_size_range, default=_size_range[1], doc=\"\"\"\n",
    "        Width (in pixels) of the images to generate\"\"\")\n",
    "    \n",
    "    height = param.Selector(_size_range, default=_size_range[1], doc=\"\"\"\n",
    "        Height (in pixels) of the images to generate\"\"\")\n",
    "    \n",
    "    guidance_scale = param.Number(bounds=(5, 10), softbounds=(7, 8.5), step=0.1, default=7.5, doc=\"\"\"\n",
    "        How closely the model should try to match the prompt, at the \n",
    "        potential expense of image quality or diversity.\n",
    "        Also known as CFG (Classifier-free guidance scale).\"\"\")\n",
    "    \n",
    "    num_steps = param.Integer(label='# of steps', bounds=(10, 75), default=30, doc=\"\"\"\n",
    "        How many denoising steps to take. \n",
    "        More steps takes longer but gives a more-refined image.\"\"\")\n",
    "\n",
    "    seed = param.Integer(label='Random seed', default=1,\n",
    "                         bounds=random_int_range, step=10, precedence=1, doc=\"\"\"\n",
    "        Seed controlling the noise values generated.\"\"\")\n",
    " \n",
    "    generate = param.Event(precedence=1)\n",
    "    \n",
    "    param.depends(\"generate\")\n",
    "    def __call__(self, **params):\n",
    "        p = param.ParamOverrides(self, params)\n",
    "        pipe = pipelines[p.model]\n",
    "        \n",
    "        res = pipe(num_inference_steps=p.num_steps, generator=pseudo_rand_gen.manual_seed(p.seed),\n",
    "                   **{k:p[k] for k in ['prompt', 'negative_prompt', 'guidance_scale', 'height', 'width']})\n",
    "\n",
    "        return res.images[0]\n",
    "    \n",
    "sd = StableDiffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a Parameterized object, we can invoke it to generate an output (uncomment if needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd(prompt=\"Chair made from twisted vines, in a manicured garden\", seed=5, guidance_scale=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `help(sd)` for all the options available from the Python prompt to control how this image is generated. You can try various prompts, such as:\n",
    "\n",
    "  1. Wildflowers on a mountain side \n",
    "  2. A dream of a distant planet, with multiple moons\n",
    "  3. Valley of flowers in the Himalayas\n",
    "  \n",
    "If the results for your prompt are not what you were hoping for, you can add hints like \"yellow\" to a negative prompt to remove yellow flowers from the image from prompt 1.\n",
    "\n",
    "Users can set the heights and widths of the generated image as they like, but note that the models were trained on images with resolution of 512x512, and image quality degrades if deviating from that resolution. \n",
    "\n",
    "For a given prompt and set of parameters, the specific image generated is deterministic, with results controlled by a random seed. Stable diffusion starts with an initial noisy image, with the goal of removing Gaussian noise in each inference step in a way that makes it more likely that the text description would apply to this image. The seed value determines the specific noise values, determining which specific image is ultimately generated. \n",
    "\n",
    "\n",
    "## Simple Panel app\n",
    "\n",
    "Now it's documented and ready to use from Python, but not everyone is comfortable with the command prompt, so let's make a [Panel](https://panel.holoviz.org) app to package up this functionality for anyone to use. The above class actually works already as a very simple Panel app generating and displaying an image determined by widgets for each parameter (uncomment if needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pn.Row(sd.param, sd.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-featured Panel app\n",
    "\n",
    "The simple app works, but let's be a bit more ambitious and add a gallery, plus saving parameters to the URL so that we can easily select our favorite outputs and store them or send them as URL links. We'll also customize some of the appearance and behavior of the default widgets.\n",
    "\n",
    "We'll first create a little HTML-based Gallery class using Panel to hold the various images generated so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models.formatters import PrintfTickFormatter\n",
    "from panel.layout.base import ListLike\n",
    "from panel.reactive import ReactiveHTML\n",
    "from panel.viewable import Viewer, Viewable\n",
    "\n",
    "class Gallery(ListLike, ReactiveHTML):\n",
    "    \"\"\"Collection of thumbnails that, when selected, restore the associated image and its parameters\"\"\"\n",
    "    \n",
    "    objects = param.List(item_type=Viewable)\n",
    "    current = param.Integer(default=None)\n",
    "    margin = param.Integer(0)\n",
    "\n",
    "    _template = \"\"\"\n",
    "    <div id=\"gallery\" style=\"display: grid; width: 350; height: 550; grid-template-columns: 1fr 1fr 1fr;\">\n",
    "    {% for img in objects %}\n",
    "      <div id=\"img\" name=\"{{ img.name }}\" onclick=${script('click')}>${img}</div>\n",
    "    {% endfor %}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    _scripts = {\n",
    "        'click': \"\"\"\n",
    "          const id = event.target.parentNode.parentNode.parentNode.id;\n",
    "          data.current = Number(id.split('-')[1]);\n",
    "          \"\"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a more full-featured Panel application using this gallery and the above Parameterized class.\n",
    "\n",
    "When rendered with a template, the sidebar should ideally start out collapsed with only the `Prompt` text box visible. Opening the sidebar provides more options. \n",
    "\n",
    "By default this full-featured class randomizes the seed for each new image generated, but previously generated images can be reproduced if the seed value is specified along with the prompt and other parameters. To make it simple to return to specific images, the app URL is updated with the seed used to generate that image, so that returning to that URL will reproduce that specific image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelUI(Viewer):\n",
    "    model = param.Parameter(StableDiffusion())\n",
    "    gallery = param.ClassSelector(class_=Gallery, default=Gallery(min_height=100), precedence=-1)\n",
    "    generate_image = param.Event(precedence=1)\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.history = deque(maxlen=15)\n",
    "        super().__init__(**params)\n",
    "        self.gallery.param.watch(self._restore_history, 'current')\n",
    "        self._restore = False\n",
    "        self._image_container = pn.pane.PNG(style={'border': '1px solid black'}, \n",
    "                                            height=self.model.height,\n",
    "                                            width=self.model.width)\n",
    "        # ensure seed always starts out being set\n",
    "        self.model.seed = random.randint(*self.model.param.seed.bounds)\n",
    "        # internal variable used to ignore repeat event on generate if prompt triggers callback\n",
    "        self._prompt_event = False\n",
    "        self._on_load()\n",
    "\n",
    "    @contextmanager\n",
    "    def _toggle(self, attr: str, value: bool):\n",
    "        # toggle state of bool attribute inside context\n",
    "        # if exception raised by code inside the contextmanager, set state back to original and rethrow\n",
    "        init_state = getattr(self, attr)\n",
    "        try:\n",
    "            setattr(self, attr, value)\n",
    "            yield\n",
    "            setattr(self, attr, not(value))\n",
    "        except Exception as ex:\n",
    "            setattr(self, attr, init_state)\n",
    "            raise ex\n",
    "\n",
    "    def _update_query_params(self):\n",
    "        \"\"\"\n",
    "        Remove all params first since update_query will only update the non-default values. \n",
    "        If the current URL has non-default values, those will be incorrect unless it is first cleared\n",
    "        \"\"\"\n",
    "        pn.state.location.search = ''\n",
    "        pn.state.location.update_query(**self._url_params)\n",
    "\n",
    "    def _update_image_container(self, image):\n",
    "        \"\"\"update the object and the container size\"\"\"\n",
    "        self._image_container.object = image\n",
    "        self._image_container.height = self.model.height\n",
    "        self._image_container.width  = self.model.width\n",
    "\n",
    "\n",
    "    def _restore_history(self, event):\n",
    "        \"\"\"\n",
    "        Load image from cache and update URL to reflect parameters used to generate image.\n",
    "        Also update the seed in the end similar so generating another image does not\n",
    "        recreate the restored image from history.\n",
    "        \"\"\"\n",
    "        if event.new is None:\n",
    "            return\n",
    "        self.gallery.current = None\n",
    "        state, image = self.history[event.new]\n",
    "        # discard_events will not allow widgets to update\n",
    "        with self._toggle('_restore', value=True):\n",
    "            self.model.param.update(state)\n",
    "        self._update_image_container(image)\n",
    "        self._update_query_params()\n",
    "        # Also update the seed so `generate_image` doesn't recreate same image\n",
    "        self.model.seed = random.randint(*self.model.param.seed.bounds)\n",
    " \n",
    "    @property\n",
    "    def _state(self):\n",
    "        return {k: v for k, v in self.model.param.values().items() if k != 'name'}\n",
    "    \n",
    "    @property\n",
    "    def _url_params(self):\n",
    "        # only capture state that deviates from default\n",
    "        state = {key: getattr(self.model, key) for key, val in self.model.param.defaults().items()\n",
    "                 if key != 'name' and getattr(self.model, key) != val}\n",
    "        return state\n",
    "    \n",
    "    def _on_load(self):\n",
    "        if pn.state.location and pn.state.location.query_params:\n",
    "            self.model.param.update(pn.state.location.query_params)\n",
    "            self.param.trigger('generate_image')\n",
    "\n",
    "    @param.depends('model.prompt', 'generate_image', watch=True)\n",
    "    def image(self):\n",
    "        if self._restore or not self.model.prompt:\n",
    "            return\n",
    "\n",
    "        # user entered prompt, then hit generate; callback invoked on 'prompt';\n",
    "        # now event triggered from generate\n",
    "        if self._prompt_event and self.generate_image:\n",
    "            self._prompt_event = False\n",
    "            return\n",
    "        self._prompt_event = True if not self.generate_image else False\n",
    "\n",
    "        with exec_time(f\"Generate {self.model.prompt}\"):\n",
    "            image = self.model()\n",
    "            image_seed = self.model.seed\n",
    "\n",
    "        if len(self.gallery) == self.history.maxlen:\n",
    "            # Oldest element from history will be dropped\n",
    "            self.gallery.remove(self.gallery[0])\n",
    "        \n",
    "        self.gallery.append(pn.pane.PNG(image.resize((100, 100))))\n",
    "        # store full state in history\n",
    "        self.history.append((self._state, image))\n",
    "\n",
    "        self._update_query_params()\n",
    "        # update seed at the end\n",
    "        self.model.seed = random.randint(*self.model.param.seed.bounds)\n",
    "        self._update_image_container(image)\n",
    "\n",
    "    def _sidebar_widgets(self):\n",
    "        return pn.Param(self.model.param, widgets = {\n",
    "                'height': pn.widgets.DiscreteSlider,\n",
    "                'width' : pn.widgets.DiscreteSlider,\n",
    "                'guidance_scale': {'formatter': PrintfTickFormatter(format='%.1f')},\n",
    "                'seed': pn.widgets.IntInput,\n",
    "                'prompt': {'visible': False},\n",
    "                'negative_prompt': {'visible': False},\n",
    "                'generate': {'visible': False}})\n",
    "\n",
    "    def _main_panel(self):\n",
    "        return pn.Column(pn.Row(pn.Column(self.model.param.prompt, self.model.param.negative_prompt, \n",
    "                                          sizing_mode='stretch_width'),\n",
    "                                pn.Param(self.param.generate_image, \n",
    "                                         widgets={'generate_image': {'button_type': 'success', \n",
    "                                                                     'height': 110, 'width': 30}})),\n",
    "                         pn.Row(pn.panel(self._image_container, loading_indicator=True), self.gallery))\n",
    "    \n",
    "    def __panel__(self):\n",
    "        return pn.Row(\n",
    "            pn.Column(self._sidebar_widgets()),\n",
    "            pn.Column(self._main_panel(), sizing_mode='stretch_width'))\n",
    "\n",
    "    \n",
    "sdui = ModelUI(name='Stable Diffusion with Panel UI')\n",
    "\n",
    "sdui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above app should work well in a notebook cell, but when we serve this as a standalone web page, it's nice to embed it in a full-page template (not shown here in the notebook for formatting reasons):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo_pn = \"\"\"<a href=\"http://panel.pyviz.org\">\n",
    "    <img src=\"https://panel.pyviz.org/_static/logo_stacked.png\" \n",
    "    width=108 height=91 align=\"left\" margin=10px>\"\"\"\n",
    "\n",
    "logo_diffusers = \"\"\"<a href=\"https://huggingface.co/docs/diffusers/index\">\n",
    "    <img src=\"./thumbnails/diffusers_logo.png\" \n",
    "    width=198 height=102 align=\"left\" margin=10px>\"\"\"\n",
    "\n",
    "desc = \"\"\"\n",
    "    The <a href=\"http://panel.pyviz.org\">Panel</a> library from \n",
    "    <a href=\"https://holoviz.org/\">HoloViz</a> \n",
    "    lets you make widget-controlled apps. This Panel app lets you use the\n",
    "    <a href=\"https://huggingface.co/docs/diffusers/index\">diffusers</a> library to\n",
    "    generate images from pretrained diffusion models.\"\"\"\n",
    "\n",
    "template = pn.template.MaterialTemplate(title=sdui.name)\n",
    "\n",
    "template.sidebar.append(pn.Column(pn.Row(logo_diffusers, logo_pn),\n",
    "                                  pn.panel(desc, width=300, margin=(20, 5)),\n",
    "                                  sdui._sidebar_widgets()))\n",
    "\n",
    "template.main.append(pn.Column(sdui._main_panel(), sizing_mode='stretch_width'))\n",
    "\n",
    "template.servable();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can launch and share this app with `panel serve stable_diffusion.ipynb` or `anaconda-project run dashboard` or `anaconda-project run dashboard-m1` !"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

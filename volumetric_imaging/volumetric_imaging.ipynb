{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc47db48-cd14-4874-a377-e4c13de91cdd",
   "metadata": {
    "panel-layout": {
     "height": 106.01666259765625,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Volumetric Imaging\n",
    "\n",
    "<img \n",
    "    src=\"./assets/volumetric_imaging_header.png\" \n",
    "    alt=\"Volumetric Imaging\" \n",
    "    align=\"center\" \n",
    "    style=\"border: 2px solid #ccc; border-radius: 8px; padding: 5px; width: 100%; box-shadow: 0px 4px 8px rgba(0,0,0,0.1);\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81c950-38e8-4c18-aec0-63ce70c34b1f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "panel-layout": {
     "height": 345,
     "visible": true,
     "width": 100
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<div style=\"display: flex; justify-content: center; padding: 10px;\">\n",
    "    <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/HFHPadEl0FE?si=li5orDrvBJ6ufYZp\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b92a30-50eb-4d00-ad83-0354c947f767",
   "metadata": {
    "panel-layout": {
     "height": 779.4500122070312,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "**Volumetric imaging** refers to techniques that capture or reconstruct data in three dimensions, enabling researchers to study the internal structures and spatial relationships within a sample. For instance, in neuroscience, volumetric imaging is used to reconstruct the intricate spatial arrangements of neurons and synapses in the brain. This ability to explore spatial depth and organization makes it an essential tool in fields like biology, neuroscience, and materials science.\n",
    "\n",
    "One of the most powerful volumetric imaging techniques is **electron microscopy** ([EM](https://en.wikipedia.org/wiki/Electron_microscope)). EM uses a beam of electrons to create high-resolution images at the nanometer scale, enabling the exploration of fine structural details of biological specimens such as cells, tissues, and molecular structures. However, handling and visualizing the massive datasets generated by EM poses significant challenges due to their size and complexity.\n",
    "\n",
    "### Introducing **Neuroglancer**\n",
    "\n",
    "[Neuroglancer](https://github.com/google/neuroglancer), developed by Google, is a browser-based 3D viewer tailored for volumetric datasets. Some key features include:\n",
    "\n",
    "- **Interactive Visualization:** Smoothly navigate large, multi-dimensional volumes.\n",
    "- **Customizable Layers:** Overlay raw images, segmented regions, and annotations as separate layers.\n",
    "- **Web-Based Interface:** Open a Neuroglancer session directly in your browserâ€”no special software needed.\n",
    "\n",
    "Neuroglancer was originally created for neuroscientists studying complex neural circuits. However, its capabilities are widely relevant to anyone dealing with large volumetric data.\n",
    "\n",
    "### Integrating Neuroglancer with **Jupyter Notebooks**\n",
    "\n",
    "While Neuroglancer is a powerful tool for exploring large volumes, it is typically used as a standalone application. Researchers often utilize **Jupyter Notebooks** to conduct reproducible research and combine code, data analysis, and visualizations. Embedding Neuroglancer into a Jupyter Notebook provides several important benefits:\n",
    "\n",
    "- **Single-Environment Workflow:** Code, analysis, and interactive visualization live together in the same environment.\n",
    "- **Reproducibility:** You can share notebooks that not only contain the analysis steps but also embedded views of the dataset.\n",
    "- **Collaboration:** Colleagues can open the same notebook and interact with the volumetric data directly.\n",
    "\n",
    "### Using **HoloViz Panel** for the Integration\n",
    "\n",
    "Panel provides a flexible way to embed web-based tools. With it, you can:\n",
    "\n",
    "- Put the Neuroglancer viewer right inside a notebook cell.\n",
    "- Add widgets for controlling Neuroglancer parameters (layers, position, segmentation).\n",
    "- Integrate Neuroglancer views with other visualizations, annotations, or computational results side-by-side.\n",
    "\n",
    "### Quick-Start with the **Panel-Neuroglancer** Package\n",
    "\n",
    "To simplify the process, the class that integrates Neuroglancer with Panel is available as an installable Python package called [Panel-Neuroglancer](https://github.com/panel-extensions/panel-neuroglancer).\n",
    "\n",
    "By installing and using this package, you can avoid manually defining the class code. Simply import the package and start visualizing your data. We'll demonstrate the out-of-the-box usage first, followed by instructions on how to customize or rebuild the integration if needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "| Topic | Type | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Panel-Neuroglancer Repo](https://panel.holoviz.org/) | Prerequisite | Awareness of installation and latest development |\n",
    "| [Neuroglancer Repo](https://github.com/google/neuroglancer) | Prerequisite | Neuroglancer web app guidance |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f77667-f42b-42f6-a13d-5abbe589d7ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T17:25:02.532910Z",
     "start_time": "2024-03-29T17:25:02.529856Z"
    },
    "panel-layout": {
     "height": 50.850006103515625,
     "visible": false,
     "width": 100
    }
   },
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a8253-e6da-485d-96cd-ce0e783ac00d",
   "metadata": {
    "panel-layout": {
     "height": 101,
     "visible": false,
     "width": 79.249
    }
   },
   "outputs": [],
   "source": [
    "import neuroglancer\n",
    "import panel as pn\n",
    "import param\n",
    "from neuroglancer.viewer import Viewer\n",
    "from panel.custom import PyComponent\n",
    "from panel_neuroglancer import Neuroglancer\n",
    "\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc64a149-d29f-4662-85da-22782dd9defc",
   "metadata": {},
   "source": [
    "## Using Panel-Neuroglancer\n",
    "Once installed, using Panel-Neuroglancer is straightforward. You can launch a Neuroglancer viewer in two main ways:\n",
    "\n",
    "**Approach 1: Load Viewer State from a URL**  \n",
    "Perfect if a collaborator sends you a Neuroglancer link that already has data and layers configured. Just paste that URL into the widget and load it directly.\n",
    "\n",
    "**Approach 2: Start from a Pre-Configured Viewer**\n",
    "Ideal if you want programmatic control. You create a `neuroglancer.Viewer`, set its layers and parameters with Python code, and then display it using the `panel-neuroglancer.Neuroglancer` class.\n",
    "\n",
    "### Approach 1: Launch Viewer from a URL\n",
    "\n",
    "You can either:\n",
    "\n",
    "- Pass a valid [Neuroglancer URL](https://github.com/google/neuroglancer#examples) to `Neuroglancer(source=<URL>)`.\n",
    "- Launch a blank viewer using `Neuroglancer()`, paste the URL into the text input, and hit `Load`.\n",
    "\n",
    "Optionally, Panel-Neuroglancer includes a predefined `demo` URL loader button (or `load_demo=True` when instantiating) to quickly load an example dataset and state. You can find example URLs in the [Neuroglancer repository](https://github.com/google/neuroglancer#examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c05fb-c167-4992-9304-acb2b809292a",
   "metadata": {},
   "source": [
    "<img \n",
    "    src=\"./assets/approach1.png\" \n",
    "    alt=\"panel-neuroglancer\" \n",
    "    align=\"right\" \n",
    "    width=\"80%\">\n",
    "\n",
    "**Here's a static snapshot of what the next cell produces. ðŸ‘‰**\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e94acb-a658-4544-8bc3-eb4302982851",
   "metadata": {},
   "outputs": [],
   "source": [
    "Neuroglancer(show_state=True, load_demo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8112c-dcdd-4fbb-a931-7916a0792f4e",
   "metadata": {},
   "source": [
    "## Approach 2: Displaying a Pre-Configured Viewer\n",
    "\n",
    "Alternatively, you can create a `neuroglancer.viewer.Viewer` object, specify layers and other settings, and then provide this as the `source` parameter. This allows you to set up the viewer programmatically and then embed it within the context of the notebook.\n",
    "\n",
    "Below:\n",
    "- We create a Neuroglancer `Viewer` instance\n",
    "- Within a transaction (`viewer.txn()`), we add layers to the viewer:\n",
    "  - An image layer from a precomputed data source\n",
    "  - A segmentation layer\n",
    "- We then pass this configured viewer to our `Neuroglancer` class\n",
    "- The viewer is embedded within the Panel app and displayed in the notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195dc09b-7fbd-4940-a451-a6247b0216de",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = neuroglancer.Viewer()\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    # Add an image layer from a precomputed data source\n",
    "    s.layers[\"image\"] = neuroglancer.ImageLayer(\n",
    "        source=\"precomputed://gs://neuroglancer-janelia-flyem-hemibrain/emdata/clahe_yz/jpeg\",\n",
    "    )\n",
    "    # Add a segmentation layer\n",
    "    s.layers[\"segmentation\"] = neuroglancer.SegmentationLayer(\n",
    "        source=\"precomputed://gs://neuroglancer-janelia-flyem-hemibrain/v1.1/segmentation\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251278f8-4634-49b1-a2ba-cb95fb7b8728",
   "metadata": {},
   "source": [
    "<img \n",
    "    src=\"./assets/approach2.png\" \n",
    "    alt=\"Panel Neuroglancer load from neuroglancer.viewer.Viewer\"\n",
    "    align=\"right\" \n",
    "    width=\"80%\">\n",
    "\n",
    "**Here's a static snapshot of what the next cell produces. ðŸ‘‰**\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a63a4-a19f-435b-a691-07e3f82a9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Neuroglancer(source=viewer, show_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a50727-8c91-4d88-a82d-626e5a7715ba",
   "metadata": {
    "panel-layout": {
     "height": 102.5,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Customizing the `Neuroglancer` Class\n",
    "\n",
    "The Panel-Neuroglancer package will likely meet most of your needs out of the box. However, if you'd like to customize or extend the classâ€”or simply understand how it worksâ€”you can easily reconstruct it directly in the notebook. Customization lets you fine-tune the interface, add specific features, or streamline the user experience for your workflows.\n",
    "\n",
    "Our class below will create a Panel object that includes the Neuroglancer viewer embedded within an iframe, along with controls to load a Neuroglancer state from a URL, display the current state JSON, and generate shareable links.\n",
    "\n",
    "As an example of customization, imagine receiving a `NEW_URL` from a colleague and deciding to simplify the interface by reducing the number of UI elements. By commenting out a few lines of code, you can remove the `Demo` loading feature and hide the URL `Load` widget, leaving only the JSON state panel, shareable state URL dropdown, and the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82c0c5-1e5d-4acc-ad91-e3052c273c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNeuroglancer(PyComponent):\n",
    "    \"\"\"\n",
    "    CustomNeuroglancer is a Panel component for visualizing and interacting with a Neuroglancer Viewer\n",
    "    (without the demo loading stuff).\n",
    "\n",
    "    The component can be initialized from a URL or a `neuroglancer.viewer.Viewer` instance.\n",
    "    \"\"\"\n",
    "\n",
    "    show_state = param.Boolean(default=False, doc=\"\"\"\n",
    "        Provides a collapsible card widget under the viewer that displays the viewer's state.\"\"\")\n",
    "\n",
    "    url = param.String(default=None, doc=\"\"\"\n",
    "        The URL public URL of the Neuroglancer Viewer.\"\"\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        source=None,\n",
    "        # load_demo=False,\n",
    "        **params,\n",
    "    ):\n",
    "        viewer = None\n",
    "        if isinstance(source, str):\n",
    "            params['url'] = source\n",
    "        elif isinstance(source, Viewer):\n",
    "            params['url'] = source.get_viewer_url()\n",
    "            viewer = source\n",
    "        elif source is not None:\n",
    "            raise ValueError('Neuroglancer source must be a URL or neuroglancer Viewer instance')\n",
    "        self._source_not_provided = source is None\n",
    "        super().__init__(**params)\n",
    "        if viewer is None:\n",
    "            viewer = neuroglancer.Viewer()\n",
    "        self.viewer = viewer\n",
    "\n",
    "        self._setup_ui_components()\n",
    "        self._configure_viewer()\n",
    "        self._setup_callbacks()\n",
    "\n",
    "        if isinstance(source, str):\n",
    "            self._load_state_from_url(source)\n",
    "        # if load_demo:\n",
    "        #     self._load_demo()\n",
    "\n",
    "    def _setup_ui_components(self):\n",
    "        self.url_input = pn.widgets.TextInput.from_param(\n",
    "            self.param.url,\n",
    "            placeholder=\"Enter a Neuroglancer URL and click Load\",\n",
    "            name=\"Input URL\",\n",
    "            width=700,\n",
    "        )\n",
    "\n",
    "        self.load_button = pn.widgets.Button(\n",
    "            name=\"Load\", button_type=\"primary\", width=75\n",
    "        )\n",
    "        # self.demo_button = pn.widgets.Button(\n",
    "        #     name=\"Demo\", button_type=\"warning\", width=75\n",
    "        # )\n",
    "\n",
    "        self.json_pane = pn.pane.JSON(\n",
    "            {}, theme=\"light\", depth=2, name=\"Viewer State\", sizing_mode='stretch_both'\n",
    "        )\n",
    "\n",
    "        self.shareable_url_pane = pn.pane.Markdown(\"**Shareable URL:**\")\n",
    "        self.local_url_pane = pn.pane.Markdown(\"**Local URL:**\")\n",
    "\n",
    "        self.iframe = pn.pane.HTML(\n",
    "            sizing_mode=\"stretch_both\",\n",
    "            aspect_ratio=self.param.aspect_ratio,\n",
    "            margin=0,\n",
    "            min_height=800,\n",
    "            styles={\"resize\": \"both\", \"overflow\": \"hidden\"},\n",
    "        )\n",
    "\n",
    "    def _configure_viewer(self):\n",
    "        self._update_local_url()\n",
    "        self._update_iframe_with_local_url()\n",
    "\n",
    "    def _setup_callbacks(self):\n",
    "        self.load_button.on_click(self._load_url)\n",
    "        # self.demo_button.on_click(self._load_demo)\n",
    "        self.viewer.shared_state.add_changed_callback(self._on_viewer_state_changed)\n",
    "\n",
    "    # def _load_demo(self, event=None):\n",
    "    #     self.url = DEMO_URL\n",
    "    #     self._load_state_from_url(self.url)\n",
    "\n",
    "    def _load_url(self, event=None):\n",
    "        self._load_state_from_url(self.url)\n",
    "\n",
    "    def _load_state_from_url(self, url):\n",
    "        try:\n",
    "            new_state = self._parse_state_from_url(url)\n",
    "            self.viewer.set_state(new_state)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Neuroglancer state: {e}\")  # noqa\n",
    "\n",
    "    def _parse_state_from_url(self, url):\n",
    "        return neuroglancer.parse_url(url)\n",
    "\n",
    "    def _on_viewer_state_changed(self):\n",
    "        self._update_shareable_url()\n",
    "        self._update_json_pane()\n",
    "\n",
    "    def _update_shareable_url(self):\n",
    "        self.url = shareable_url = neuroglancer.to_url(self.viewer.state)\n",
    "        self.shareable_url_pane.object = self._generate_dropdown_markup(\n",
    "            \"Shareable URL\", shareable_url\n",
    "        )\n",
    "\n",
    "    def _update_local_url(self):\n",
    "        self.local_url_pane.object = self._generate_dropdown_markup(\n",
    "            \"Local URL\", self.viewer.get_viewer_url()\n",
    "        )\n",
    "\n",
    "    def _update_iframe_with_local_url(self):\n",
    "        iframe_style = (\n",
    "            'frameborder=\"0\" scrolling=\"no\" marginheight=\"0\" marginwidth=\"0\" '\n",
    "            'style=\"width:100%; height:100%; min-width:500px; min-height:500px;\"'\n",
    "        )\n",
    "        self.iframe.object = (\n",
    "            f'<iframe src=\"{self.viewer.get_viewer_url()}\" {iframe_style}></iframe>'\n",
    "        )\n",
    "\n",
    "    def _update_json_pane(self):\n",
    "        self.json_pane.object = self.viewer.state.to_json()\n",
    "\n",
    "    def _generate_dropdown_markup(self, title, url):\n",
    "        return f\"\"\"\n",
    "        <details>\n",
    "            <summary><b>{title}:</b></summary>\n",
    "            <a href=\"{url}\" target=\"_blank\">{url}</a>\n",
    "        </details>\n",
    "        \"\"\"\n",
    "\n",
    "    def __panel__(self):\n",
    "        controls = pn.Column(\n",
    "            # pn.Row(self.demo_button, self.load_button, visible=self._source_not_provided),\n",
    "            # pn.Row(self.url_input, visible=self._source_not_provided),\n",
    "            # self.local_url_pane,\n",
    "            self.shareable_url_pane\n",
    "        )\n",
    "        state_widget = pn.Card(\n",
    "            self.json_pane,\n",
    "            title=\"State\",\n",
    "            collapsed=False,\n",
    "            visible=self.param.show_state,\n",
    "            styles={\"background\": \"WhiteSmoke\"},\n",
    "            max_width=350\n",
    "        )\n",
    "        return pn.Column(\n",
    "            controls,\n",
    "            pn.Row(state_widget, self.iframe),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d864fe66-15b1-43c4-bef9-d295b356e4ba",
   "metadata": {},
   "source": [
    "### How This Custom Class Works\n",
    "\n",
    "Here is a summary of the key aspect of this custom Panel component:\n",
    "\n",
    "- **Constructing the Panel Layout:**  The class inherits from PyComponent, a mechanism that lets us assemble multiple Panel components into a unified widget. The `__panel__` method defines the final layout: a card showing the viewer state (if requested) next to an iframe embedding the Neuroglancer viewer.\n",
    "\n",
    "- **Viewer State Synchronization:** When the Neuroglancer viewerâ€™s state changes, the callback (`_on_viewer_state_changed`) updates the JSON pane and shareable URL, maintaining alignment between the viewer and the notebook widgets. The `shared_state` object in the viewer enables this synchronization by alerting Panel to any changes within Neuroglancer.\n",
    "\n",
    "- **URL Parsing and Generation:** Neuroglancer states can be encoded in URLs. By calling `neuroglancer.parse_url()`, we load an existing state from a shareable link. Conversely, `neuroglancer.to_url()` generates a new URL from the current state, making it easy to share your exact view with others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab67ed5-625f-4be7-8c86-a5657c86a065",
   "metadata": {
    "panel-layout": {
     "height": 68.30000305175781,
     "visible": false,
     "width": 100
    }
   },
   "source": [
    "<img \n",
    "    src=\"./assets/CustomNeuroglancer.png\" \n",
    "    alt=\"Panel CustomNeuroglancer\"\n",
    "    align=\"right\" \n",
    "    width=\"80%\">\n",
    "\n",
    "**Here's a static snapshot of what the next cell produces. ðŸ‘‰**\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db73dd-f7e3-4896-b76a-a6743042713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_URL = \"https://fafb-dot-neuroglancer-demo.appspot.com/#!%7B%22dimensions%22:%7B%22x%22:%5B4e-9%2C%22m%22%5D%2C%22y%22:%5B4e-9%2C%22m%22%5D%2C%22z%22:%5B4e-8%2C%22m%22%5D%7D%2C%22position%22:%5B109421.8984375%2C41044.6796875%2C5417%5D%2C%22crossSectionScale%22:2.1875%2C%22projectionOrientation%22:%5B-0.08939177542924881%2C-0.9848012924194336%2C-0.07470247149467468%2C0.12882165610790253%5D%2C%22projectionScale%22:27773.019357116023%2C%22layers%22:%5B%7B%22type%22:%22image%22%2C%22source%22:%22precomputed://gs://neuroglancer-fafb-data/fafb_v14/fafb_v14_orig%22%2C%22tab%22:%22source%22%2C%22name%22:%22fafb_v14%22%2C%22visible%22:false%7D%2C%7B%22type%22:%22image%22%2C%22source%22:%22precomputed://gs://neuroglancer-fafb-data/fafb_v14/fafb_v14_clahe%22%2C%22tab%22:%22source%22%2C%22name%22:%22fafb_v14_clahe%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%22precomputed://gs://fafb-ffn1-20190805/segmentation%22%2C%22tab%22:%22source%22%2C%22segments%22:%5B%22710435991%22%5D%2C%22name%22:%22fafb-ffn1-20190805%22%7D%2C%7B%22type%22:%22annotation%22%2C%22source%22:%22precomputed://gs://neuroglancer-20191211_fafbv14_buhmann2019_li20190805%22%2C%22tab%22:%22rendering%22%2C%22annotationColor%22:%22#cecd11%22%2C%22shader%22:%22#uicontrol%20vec3%20preColor%20color%28default=%5C%22blue%5C%22%29%5Cn#uicontrol%20vec3%20postColor%20color%28default=%5C%22red%5C%22%29%5Cn#uicontrol%20float%20scorethr%20slider%28min=0%2C%20max=1000%29%5Cn#uicontrol%20int%20showautapse%20slider%28min=0%2C%20max=1%29%5Cn%5Cnvoid%20main%28%29%20%7B%5Cn%20%20setColor%28defaultColor%28%29%29%3B%5Cn%20%20setEndpointMarkerColor%28%5Cn%20%20%20%20vec4%28preColor%2C%200.5%29%2C%5Cn%20%20%20%20vec4%28postColor%2C%200.5%29%29%3B%5Cn%20%20setEndpointMarkerSize%285.0%2C%205.0%29%3B%5Cn%20%20setLineWidth%282.0%29%3B%5Cn%20%20if%20%28int%28prop_autapse%28%29%29%20%3E%20showautapse%29%20discard%3B%5Cn%20%20if%20%28prop_score%28%29%3Cscorethr%29%20discard%3B%5Cn%7D%5Cn%5Cn%22%2C%22shaderControls%22:%7B%22scorethr%22:80%7D%2C%22linkedSegmentationLayer%22:%7B%22pre_segment%22:%22fafb-ffn1-20190805%22%2C%22post_segment%22:%22fafb-ffn1-20190805%22%7D%2C%22filterBySegmentation%22:%5B%22post_segment%22%2C%22pre_segment%22%5D%2C%22name%22:%22synapses_buhmann2019%22%7D%2C%7B%22type%22:%22image%22%2C%22source%22:%22n5://gs://fafb-v14-synaptic-clefts-heinrich-et-al-2018-n5/synapses_dt_reblocked%22%2C%22tab%22:%22source%22%2C%22opacity%22:0.73%2C%22shader%22:%22void%20main%28%29%20%7BemitRGBA%28vec4%280.0%2C0.0%2C1.0%2CtoNormalized%28getDataValue%28%29%29%29%29%3B%7D%22%2C%22name%22:%22clefts_Heinrich_etal%22%2C%22visible%22:false%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%22precomputed://gs://neuroglancer-fafb-data/elmr-data/FAFBNP.surf/mesh#type=mesh%22%2C%22tab%22:%22source%22%2C%22segments%22:%5B%221%22%2C%2210%22%2C%2211%22%2C%2212%22%2C%2213%22%2C%2214%22%2C%2215%22%2C%2216%22%2C%2217%22%2C%2218%22%2C%2219%22%2C%222%22%2C%2220%22%2C%2221%22%2C%2222%22%2C%2223%22%2C%2224%22%2C%2225%22%2C%2226%22%2C%2227%22%2C%2228%22%2C%2229%22%2C%223%22%2C%2230%22%2C%2231%22%2C%2232%22%2C%2233%22%2C%2234%22%2C%2235%22%2C%2236%22%2C%2237%22%2C%2238%22%2C%2239%22%2C%224%22%2C%2240%22%2C%2241%22%2C%2242%22%2C%2243%22%2C%2244%22%2C%2245%22%2C%2246%22%2C%2247%22%2C%2248%22%2C%2249%22%2C%225%22%2C%2250%22%2C%2251%22%2C%2252%22%2C%2253%22%2C%2254%22%2C%2255%22%2C%2256%22%2C%2257%22%2C%2258%22%2C%2259%22%2C%226%22%2C%2260%22%2C%2261%22%2C%2262%22%2C%2263%22%2C%2264%22%2C%2265%22%2C%2266%22%2C%2267%22%2C%2268%22%2C%2269%22%2C%227%22%2C%2270%22%2C%2271%22%2C%2272%22%2C%2273%22%2C%2274%22%2C%2275%22%2C%228%22%2C%229%22%5D%2C%22name%22:%22neuropil-regions-surface%22%2C%22visible%22:false%7D%2C%7B%22type%22:%22mesh%22%2C%22source%22:%22vtk://https://storage.googleapis.com/neuroglancer-fafb-data/elmr-data/FAFB.surf.vtk.gz%22%2C%22tab%22:%22source%22%2C%22shader%22:%22void%20main%28%29%20%7BemitRGBA%28vec4%281.0%2C%200.0%2C%200.0%2C%200.5%29%29%3B%7D%22%2C%22name%22:%22neuropil-full-surface%22%2C%22visible%22:false%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%5B%7B%22url%22:%22precomputed://gs://fafb-ffn1-20190805/segmentation%22%2C%22subsources%22:%7B%22default%22:true%2C%22bounds%22:true%7D%2C%22enableDefaultSubsources%22:false%7D%2C%22precomputed://gs://fafb-ffn1-20190805/segmentation/skeletons_32nm%22%5D%2C%22tab%22:%22source%22%2C%22selectedAlpha%22:0%2C%22segments%22:%5B%224613663523%22%5D%2C%22name%22:%22skeletons_32nm%22%2C%22visible%22:false%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%22precomputed://gs://fafb-ffn1/fafb-public-skeletons%22%2C%22tab%22:%22source%22%2C%22segments%22:%5B%5D%2C%22name%22:%22public_skeletons%22%2C%22visible%22:false%7D%5D%2C%22showAxisLines%22:false%2C%22showSlices%22:false%2C%22layout%22:%22xy-3d%22%7D\"\n",
    "CustomNeuroglancer(source=NEW_URL, show_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930576dd-8485-4de8-b2dc-9ca3df12748e",
   "metadata": {},
   "source": [
    "### Standalone App Extension\n",
    "\n",
    "HoloViz Panel allows for the deployment of this complex visualization as a standalone, template-styled, interactive web application (outside of a Jupyter Notebook). Read more about Panel [here](https://panel.holoviz.org/).\n",
    "\n",
    "We'll add our plots to the `main` area of a Panel Template component and set the entire component to be `servable`.\n",
    "\n",
    "To launch the standalone app, activate the same conda environment and run `panel serve <path-to-this-file> --show` in the command line to open the application in a browser window (tip: use the `--dev` flag to auto update the app when the file changes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0ae50-28a6-48e8-adb4-7d7831a94cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "servable_app = pn.template.FastListTemplate(\n",
    "    title = \"Panel Neuroglancer for Volumetric Imaging\",\n",
    "    main = Neuroglancer(show_state=True, load_demo=True),\n",
    "    main_layout=None,\n",
    "    theme=\"dark\",\n",
    "    accent=\"#bb5457\"\n",
    ").servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1247343e-44b5-46a8-a05d-511d1a392e9d",
   "metadata": {
    "panel-layout": {
     "height": 294.66668701171875,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Explore Your Own Datasets:** Modify the code to load and visualize your own volumetric datasets.\n",
    "- **Extend the Application:** Integrate additional HoloViews plots or other Panel components to create a more comprehensive application. For instance, you might add controls for adjusting visualization parameters.\n",
    "- **Share and Collaborate:** Use the shareable URLs generated by the app to share specific views or states with collaborators. Embedding the application in a notebook ensures that your analysis and visualizations are reproducible and shareable.\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "| Resource | Description |\n",
    "| --- | --- |\n",
    "| [Panel Tutorials](https://panel.holoviz.org/) | Familiarity with Panel for building interactive apps |\n",
    "| [Neuroglancer Python Integration](https://github.com/google/neuroglancer/tree/master/python) | Python interface for controlling Neuroglancer |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b5019-7814-46f0-b968-c6eb28b9c40a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "panel-cell-order": [
   "cc47db48-cd14-4874-a377-e4c13de91cdd",
   "ef81c950-38e8-4c18-aec0-63ce70c34b1f",
   "e3b92a30-50eb-4d00-ad83-0354c947f767",
   "a2f77667-f42b-42f6-a13d-5abbe589d7ea",
   "c83a8253-e6da-485d-96cd-ce0e783ac00d",
   "64a50727-8c91-4d88-a82d-626e5a7715ba",
   "4dac819c-c3e9-4a51-be83-bf54b28f62b2",
   "58f1de1e-d307-4e6a-8f49-ec7f4a04cc24",
   "615b234d-e8f3-4600-826d-c1db1d820bbf",
   "9ab67ed5-625f-4be7-8c86-a5657c86a065",
   "afa26a39-e22f-4ae8-880e-559350e1bfc9",
   "2717e7f4-f098-4ba8-87a5-1e673496d740",
   "26d8d75a-4512-4d92-8c96-a5f974fc72c7",
   "94b0e8a2-4fa3-44b0-b7a4-8b43f9ad081f",
   "1247343e-44b5-46a8-a05d-511d1a392e9d"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
